{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1fcd6c3",
   "metadata": {},
   "source": [
    "# New generation datamodels and DBMSS Project\n",
    "2023 / april 2025 edition\n",
    "\n",
    "This notebook has been developed in accordance with the project guidelines provided by the professor. You can consult the guidelines at the following link: [Project Guidelines](assets/Project2023-vers1.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e01d1-ffc7-4f78-bf43-acbbe19cb409",
   "metadata": {},
   "source": [
    "## 1) Transaction Data Simulator Tool\n",
    "\n",
    "This section focuses on how the various provided scripts were combined to create a single versatile script that, through the use of parameters, is capable of generating CSV files containing all the data to be inserted into the database. We will not explain the functionality of the Python scripts or the meaning of the data generated by the tool, as these aspects are clearly detailed on the [linked page](https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_3_GettingStarted/SimulatedDataset.html).\n",
    "\n",
    "To proceed, the following Python packages and Python sources (from this project's repository) are required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5306d3-a84f-42dd-ab03-e115c192b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.append(os.path.join(os.getcwd(), '../GenerationScript/Transaction_data_simulator_code'))\n",
    "from add_frauds import add_frauds\n",
    "from generate_dataset import generate_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab3f3b",
   "metadata": {},
   "source": [
    "### 1.1) Parameters\n",
    "\n",
    "To manage the parameters for the script in a simple way, I decided to use an array of objects. Each object represents the entire configuration for creating a single database, allowing the script to create multiple databases with different characteristics and data volumes in one run.\n",
    "\n",
    "Each object in the array, so each database configuration, contains:\n",
    "- DB_name: The name of the database.\n",
    "- n_customers: The number of customers to create.\n",
    "- n_terminals: The number of terminals to create.\n",
    "- start_date: The start date for generating transaction data.\n",
    "- n_days: The number of days after the start_date to use for generating transaction data.\n",
    "- radius: The action radius for customers. A customer can only perform transactions at a terminal within their radius.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d623f6c9",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "DBs = [\n",
    "   {\n",
    "       \"DB_name\": \"DB-410KB\",\n",
    "       \"n_customers\": 500,\n",
    "       \"n_terminals\": 300,\n",
    "       \"n_days\": 7,\n",
    "       \"start_date\": '2024-12-30',\n",
    "       \"radius\": 10\n",
    "    },\n",
    "    {\n",
    "        \"DB_name\": \"DB-14MB\",\n",
    "        \"n_customers\": 200,\n",
    "        \"n_terminals\": 50,\n",
    "        \"n_days\": 700,\n",
    "        \"start_date\": '2022-01-01',\n",
    "        \"radius\": 15\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e01739-8ad8-4b0d-b4c4-479deec0a9e2",
   "metadata": {},
   "source": [
    "### 1.2) Generation Script\n",
    "\n",
    "Below is the commented code for generating the databases using the parameters defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744055c-ee97-4bd0-a459-6dd87dbbe7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to generate customer profiles table: 0.02s\n",
      "Time to generate terminal profiles table: 0.00s\n",
      "Time to associate terminals to customers: 0.32s\n",
      "Time to generate transactions: 2.69s\n",
      "Number of frauds from scenario 1: 1\n",
      "Number of frauds from scenario 2: 127\n",
      "Number of frauds from scenario 3: 46\n",
      "Database data saved in: C:\\Users\\luca.maccarini\\Desktop\\luca\\NewGenerationDBMSSProject\\Generated_DBs\\DB-410KB/\n",
      "\n",
      "Time to generate customer profiles table: 0.01s\n",
      "Time to generate terminal profiles table: 0.00s\n",
      "Time to associate terminals to customers: 0.12s\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"\"\n",
    "# Loop sui DB definiti nel file di configurazione\n",
    "for db in DBs:\n",
    "    # Generazione delle tabelle del DB usando i valori di configurazione\n",
    "    (customer_profiles_table, terminal_profiles_table, transactions_df) = generate_dataset(\n",
    "        n_customers=db[\"n_customers\"], \n",
    "        n_terminals=db[\"n_terminals\"], \n",
    "        nb_days=db[\"n_days\"], \n",
    "        start_date=db[\"start_date\"], \n",
    "        r=db[\"radius\"]\n",
    "    )\n",
    "\n",
    "    # Aggiungere frodi alle transazioni\n",
    "    transactions_df = add_frauds(customer_profiles_table, terminal_profiles_table, transactions_df)\n",
    "\n",
    "    \n",
    "    # Converto i valori della serie available_terminals dato che gli interi nella lista sono interi numpy\n",
    "    customer_profiles_table['available_terminals'] = customer_profiles_table['available_terminals'].apply(\n",
    "        lambda lst: [int(i) if isinstance(i, np.integer) else i for i in lst] if isinstance(lst, (list, np.array)) else lst\n",
    "    )\n",
    "\n",
    "    # Preparazione al salvataggio del DB\n",
    "    output_dir = os.path.join(os.getcwd(), '..', 'Generated_DBs', db[\"DB_name\"])\n",
    "\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Salvataggio dei customers\n",
    "    customer_profiles_table.to_csv(output_dir + '/customers.csv', sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "    # Salvataggio dei terminals\n",
    "    terminal_profiles_table.to_csv(output_dir + '/terminals.csv', sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "    # Salvataggio delle transactions\n",
    "    transactions_df.to_csv(output_dir + '/transactions.csv', sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "    print(f\"Database data saved in: {os.path.abspath(output_dir)}/\\n\")\n",
    "\n",
    "\n",
    "print(\"DONE! All DBs have been created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc7664f-110a-483a-b745-cf45712a853d",
   "metadata": {},
   "source": [
    "### 1.3) CSV Generati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c12f5-dbee-4269-80dc-d90249edfbae",
   "metadata": {},
   "source": [
    "Now, let's take a look at the generated CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48565d8-453d-4bc9-a6a1-219b0c0fc01c",
   "metadata": {},
   "source": [
    "#### Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcb212b5-92c1-46e0-ada7-dcdf9339fade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_customer_id</th>\n",
       "      <th>y_customer_id</th>\n",
       "      <th>mean_amount</th>\n",
       "      <th>std_amount</th>\n",
       "      <th>mean_nb_tx_per_day</th>\n",
       "      <th>available_terminals</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.881350</td>\n",
       "      <td>71.518937</td>\n",
       "      <td>62.262521</td>\n",
       "      <td>31.131260</td>\n",
       "      <td>2.179533</td>\n",
       "      <td>[29, 87]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.365480</td>\n",
       "      <td>64.589411</td>\n",
       "      <td>46.570785</td>\n",
       "      <td>23.285393</td>\n",
       "      <td>3.567092</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.366276</td>\n",
       "      <td>38.344152</td>\n",
       "      <td>80.213879</td>\n",
       "      <td>40.106939</td>\n",
       "      <td>2.115580</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.804456</td>\n",
       "      <td>92.559664</td>\n",
       "      <td>11.748426</td>\n",
       "      <td>5.874213</td>\n",
       "      <td>0.348517</td>\n",
       "      <td>[65, 94]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.021840</td>\n",
       "      <td>83.261985</td>\n",
       "      <td>78.924891</td>\n",
       "      <td>39.462446</td>\n",
       "      <td>3.480049</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>13.907270</td>\n",
       "      <td>42.690436</td>\n",
       "      <td>85.071214</td>\n",
       "      <td>42.535607</td>\n",
       "      <td>3.272133</td>\n",
       "      <td>[15, 22, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>10.241376</td>\n",
       "      <td>15.638335</td>\n",
       "      <td>33.898876</td>\n",
       "      <td>16.949438</td>\n",
       "      <td>0.301436</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>42.466300</td>\n",
       "      <td>10.761771</td>\n",
       "      <td>58.980671</td>\n",
       "      <td>29.490336</td>\n",
       "      <td>0.986228</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>59.643307</td>\n",
       "      <td>11.752564</td>\n",
       "      <td>97.708967</td>\n",
       "      <td>48.854484</td>\n",
       "      <td>3.730245</td>\n",
       "      <td>[28, 70]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>39.179694</td>\n",
       "      <td>24.217859</td>\n",
       "      <td>28.787830</td>\n",
       "      <td>14.393915</td>\n",
       "      <td>1.933574</td>\n",
       "      <td>[47]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x_customer_id  y_customer_id  mean_amount  std_amount  \\\n",
       "CUSTOMER_ID                                                          \n",
       "0                54.881350      71.518937    62.262521   31.131260   \n",
       "1                42.365480      64.589411    46.570785   23.285393   \n",
       "2                96.366276      38.344152    80.213879   40.106939   \n",
       "3                56.804456      92.559664    11.748426    5.874213   \n",
       "4                 2.021840      83.261985    78.924891   39.462446   \n",
       "...                    ...            ...          ...         ...   \n",
       "195              13.907270      42.690436    85.071214   42.535607   \n",
       "196              10.241376      15.638335    33.898876   16.949438   \n",
       "197              42.466300      10.761771    58.980671   29.490336   \n",
       "198              59.643307      11.752564    97.708967   48.854484   \n",
       "199              39.179694      24.217859    28.787830   14.393915   \n",
       "\n",
       "             mean_nb_tx_per_day available_terminals  \n",
       "CUSTOMER_ID                                          \n",
       "0                      2.179533            [29, 87]  \n",
       "1                      3.567092                 [5]  \n",
       "2                      2.115580                  []  \n",
       "3                      0.348517            [65, 94]  \n",
       "4                      3.480049                  []  \n",
       "...                         ...                 ...  \n",
       "195                    3.272133        [15, 22, 30]  \n",
       "196                    0.301436                  []  \n",
       "197                    0.986228                  []  \n",
       "198                    3.730245            [28, 70]  \n",
       "199                    1.933574                [47]  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(os.path.join(output_dir, 'customers.csv'), sep=';', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a29e7a5-d9b6-4e4b-8ef4-54d84a9ed8ee",
   "metadata": {},
   "source": [
    "#### Terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dfd3649-9afb-4440-9863-4fb1eadeba66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_terminal_id</th>\n",
       "      <th>y_terminal_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.702200</td>\n",
       "      <td>72.032449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011437</td>\n",
       "      <td>30.233257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.675589</td>\n",
       "      <td>9.233859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.626021</td>\n",
       "      <td>34.556073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.676747</td>\n",
       "      <td>53.881673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>26.329677</td>\n",
       "      <td>6.596109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>73.506596</td>\n",
       "      <td>77.217803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>90.781585</td>\n",
       "      <td>93.197207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.395157</td>\n",
       "      <td>23.436209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>61.677836</td>\n",
       "      <td>94.901632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x_terminal_id  y_terminal_id\n",
       "TERMINAL_ID                              \n",
       "0                41.702200      72.032449\n",
       "1                 0.011437      30.233257\n",
       "2                14.675589       9.233859\n",
       "3                18.626021      34.556073\n",
       "4                39.676747      53.881673\n",
       "...                    ...            ...\n",
       "95               26.329677       6.596109\n",
       "96               73.506596      77.217803\n",
       "97               90.781585      93.197207\n",
       "98                1.395157      23.436209\n",
       "99               61.677836      94.901632\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(output_dir, 'terminals.csv'), sep=';', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338c7ff-e76e-4a56-a4fd-daae427cb364",
   "metadata": {},
   "source": [
    "#### Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2384961-3d3b-40d4-b7c3-7e0a713ab315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TX_DATETIME</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th>TX_AMOUNT</th>\n",
       "      <th>TX_TIME_SECONDS</th>\n",
       "      <th>TX_TIME_DAYS</th>\n",
       "      <th>TX_FRAUD</th>\n",
       "      <th>TX_FRAUD_SCENARIO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:32:35</td>\n",
       "      <td>183</td>\n",
       "      <td>47</td>\n",
       "      <td>39.30</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:11:00</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2.08</td>\n",
       "      <td>4260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 01:56:44</td>\n",
       "      <td>55</td>\n",
       "      <td>81</td>\n",
       "      <td>35.06</td>\n",
       "      <td>7004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 01:59:15</td>\n",
       "      <td>159</td>\n",
       "      <td>2</td>\n",
       "      <td>54.22</td>\n",
       "      <td>7155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 02:47:11</td>\n",
       "      <td>128</td>\n",
       "      <td>39</td>\n",
       "      <td>96.68</td>\n",
       "      <td>10031</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235629</th>\n",
       "      <td>2024-12-30 22:46:50</td>\n",
       "      <td>141</td>\n",
       "      <td>94</td>\n",
       "      <td>71.60</td>\n",
       "      <td>94603610</td>\n",
       "      <td>1094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235630</th>\n",
       "      <td>2024-12-30 22:52:01</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>4.42</td>\n",
       "      <td>94603921</td>\n",
       "      <td>1094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235631</th>\n",
       "      <td>2024-12-30 23:03:21</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>118.22</td>\n",
       "      <td>94604601</td>\n",
       "      <td>1094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235632</th>\n",
       "      <td>2024-12-30 23:04:23</td>\n",
       "      <td>155</td>\n",
       "      <td>11</td>\n",
       "      <td>39.80</td>\n",
       "      <td>94604663</td>\n",
       "      <td>1094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235633</th>\n",
       "      <td>2024-12-30 23:23:31</td>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>53.90</td>\n",
       "      <td>94605811</td>\n",
       "      <td>1094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235634 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        TX_DATETIME  CUSTOMER_ID  TERMINAL_ID  TX_AMOUNT  \\\n",
       "TRANSACTION_ID                                                             \n",
       "0               2022-01-01 00:32:35          183           47      39.30   \n",
       "1               2022-01-01 01:11:00            8            8       2.08   \n",
       "2               2022-01-01 01:56:44           55           81      35.06   \n",
       "3               2022-01-01 01:59:15          159            2      54.22   \n",
       "4               2022-01-01 02:47:11          128           39      96.68   \n",
       "...                             ...          ...          ...        ...   \n",
       "235629          2024-12-30 22:46:50          141           94      71.60   \n",
       "235630          2024-12-30 22:52:01            8           46       4.42   \n",
       "235631          2024-12-30 23:03:21           52           94     118.22   \n",
       "235632          2024-12-30 23:04:23          155           11      39.80   \n",
       "235633          2024-12-30 23:23:31           94           10      53.90   \n",
       "\n",
       "                TX_TIME_SECONDS  TX_TIME_DAYS  TX_FRAUD  TX_FRAUD_SCENARIO  \n",
       "TRANSACTION_ID                                                              \n",
       "0                          1955             0         0                  0  \n",
       "1                          4260             0         0                  0  \n",
       "2                          7004             0         0                  0  \n",
       "3                          7155             0         0                  0  \n",
       "4                         10031             0         0                  0  \n",
       "...                         ...           ...       ...                ...  \n",
       "235629                 94603610          1094         0                  0  \n",
       "235630                 94603921          1094         0                  0  \n",
       "235631                 94604601          1094         0                  0  \n",
       "235632                 94604663          1094         0                  0  \n",
       "235633                 94605811          1094         0                  0  \n",
       "\n",
       "[235634 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(output_dir, 'transactions.csv'), sep=';', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb8392b-ce13-4d86-b5c7-d6d12aabc795",
   "metadata": {},
   "source": [
    "### 1.4) Generated CSVs\n",
    "In the project guidelines, it is requested to generate three databases with sizes of 50 MB, 100 MB, and 200 MB. The database generation script does not allow directly defining the desired database size. Instead, all the previously identified parameters must be specified. After conducting several tests, I determined the parameters required to generate the three databases with the requested sizes.\n",
    "\n",
    "It is important to note that the generated databases simulate scenarios with a high transaction volume and a limited number of customers and terminals. This characteristic reflects a worst-case scenario for our workload, which should be considered when evaluating performance.\n",
    "\n",
    "Unfortunately, none of the three databases requested by the project can be loaded on a free Neo4j Aura instance due to the excessive number of relationships, which exceeds the 400K limit. So for the purpose of this notebook and to ensure that the provided code can run without requiring a local Neo4j instance or changes to the connection settings, I have decided to use a 14MB database we previously generated with a free Neo4j Aura instance created by me. Thespite thet limitation in the final section regarding performance, the queries performed in this notebook will also be applied to databases of 50 MB, 100 MB, and 200 MB but in a local instance that doesen't have limitations.\n",
    "\n",
    "Since generating these databases is time-consuming, I will not execute the database generation script during this demonstration. However, if desired, the script can be used to generate them, below there are the parameters to generate the requested databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25e98635-503b-4cd9-860f-451457963a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "DBs = [\n",
    "    {\n",
    "        \"DB_name\": \"50MB\",\n",
    "        \"n_customers\": 1000,\n",
    "        \"n_terminals\": 500,\n",
    "        \"n_days\": 500,\n",
    "        \"start_date\": '2022-01-01',\n",
    "        \"radius\": 5\n",
    "    },\n",
    "    {\n",
    "        \"DB_name\": \"100MB\",\n",
    "        \"n_customers\": 1200,\n",
    "        \"n_terminals\": 600,\n",
    "        \"n_days\": 800,\n",
    "        \"start_date\": '2022-01-01',\n",
    "        \"radius\": 5\n",
    "    },\n",
    "    {\n",
    "        \"DB_name\": \"200MB\",\n",
    "        \"n_customers\": 2000,\n",
    "        \"n_terminals\": 1000,\n",
    "        \"n_days\": 900,\n",
    "        \"start_date\": '2022-01-01',\n",
    "        \"radius\": 5\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cd624c-46c3-4f07-a8b8-f3e58796b4f2",
   "metadata": {},
   "source": [
    "## 2) Conceptual Model\n",
    "\n",
    "To create the following conceptual model, I analyzed the CSV files generated by the *Transaction Data Simulator* tool. This analysis allowed me to understand the data's semantics and design a clear and simple structure that illustrates the relationships between the data to be stored in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7225c-f30e-4129-aa42-5f9837bd76d4",
   "metadata": {},
   "source": [
    "<img src=\"./assets/Conceptual model UML.svg\" style=\"width:800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9b0af-a1db-4aad-b8ce-ab071041fd14",
   "metadata": {},
   "source": [
    "### 2.2) Costraints\n",
    "#### Terminal\n",
    "- 0 <= `coords.x` <= 100\n",
    "- 0 <= `coords.y` <= 100\n",
    "\n",
    "#### Customer\n",
    "- 0 <= `coords.x` <= 100\n",
    "- 0 <= `coords.y` <= 100\n",
    "- `spending_mean` >= 0\n",
    "- `spending_std` >= 0\n",
    "- `transactions_per_day_mean` >= 0\n",
    "\n",
    "#### Transactions\n",
    "- `amount` > 0\n",
    "- 0 <= `fraud_scenario` <= 3\n",
    "- 0 <= `security_feeling` <= 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1cadaf-07f9-4964-8509-e3bed43d7c1c",
   "metadata": {},
   "source": [
    "## 3) Logical Model\n",
    "\n",
    "Before proceeding with the logical model, it is important to indicate which database I have chosen to manage the data and the decisions I made regarding the representation of the data to meet the workload requirements.\n",
    "\n",
    "### 3.1) Database\n",
    "As a database, I chose to use Neo4j due to the nature of the data, which suggests a graph structure. Infact, all the relationships present are of the N:N type, and such relationships are excellently handled by graph databases. \n",
    "\n",
    "Furthermore, this choice was confirmed by the workload, especially by query 3c, which involves continuous traversal of relationships up to a certain `K` value that determines when to stop. Performing this query would be extremely costly if we had to perform a join (or lookup) for each traversed relationship. \n",
    "\n",
    "Additionally, as we will see later, Cypher, Neo4j's query language, offers a library called APOC that will allow us to execute query 3c with impressive performance.\n",
    "\n",
    "### 3.2) Data representation (Workload friendly)\n",
    "Since Neo4j does not allow the definition of custom types or the insertion of objects within node properties, I decided to eliminate all custom types and implement them using primitive types. For the custom types representing objects, I created a property for each attribute with its corresponding primitive type. For enums, I used simple strings.\n",
    "\n",
    "The attribute names in the logical model differ from those in the conceptual model because they are based on those used by the *Transaction Data Simulator* tool. The meaning of any unclear or newly introduced fields can be determined by:  \n",
    "- Referring to the *Transaction Data Simulator* tool documentation for fields generated by the tool.  \n",
    "- Reading the following paragraph, where I explain the new fields I added.  \n",
    "- Consulting the project guidelines, which detail and justify the fields explicitly required in the extended database.  \n",
    "\n",
    "As we will see later, to improve the efficiency of the workload through indexing, I decided to split the `transactions.registration` field into its components: day, month, year, and time. These components are now represented as `tx_date_day`, `tx_date_month`, `tx_date_year`, and `tx_date_time`, respectively. This division was made because many queries in the workload filter data using only the month and year of the `transactions.registration` field. If I had created an index on the entire field, it would not have been used, as the filters in the queries would only utilize a subset of the entire field. Therefore, the division was made, and a composite index was created only on the year and month fields.\n",
    "\n",
    "The data types specified are those present in Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff40efb-95e5-4285-a131-1b0e61bf7a93",
   "metadata": {},
   "source": [
    "<img src=\"./assets/Logical model UML.svg\" style=\"width:800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c04e6-2e07-463d-af89-5863a1ed487a",
   "metadata": {},
   "source": [
    "### 3.3) Costraints\n",
    "#### Terminal\n",
    "- 0 <= `x_terminal_id` <= 100\n",
    "- 0 <= `y_terminal_id` <= 100\n",
    "\n",
    "#### Customer\n",
    "- 0 <= `x_customer_id` <= 100\n",
    "- 0 <= `y_customer_id` <= 100\n",
    "- `mean_amount` >= 0\n",
    "- `std_amount` >= 0\n",
    "- `mean_nb_tx_per_day` >= 0\n",
    "\n",
    "#### Transactions\n",
    "- `tx_amount` > 0\n",
    "- 0 <= `tx_fraud_scenario` <= 3\n",
    "- 0 <= `tx_security_feeling` <= 5\n",
    "- `tx_date_day`, `tx_date_month`, `tx_date_year` form a correct date type object \n",
    "- `tx_date_time` forms a correct localTime object\n",
    "- `tx_day_period` is one of the following strings [\"morning\", \"afternoon\", \"evening\", \"night\"]\n",
    "- `tx_products_type` is one of the following strings [\"high-tech\", \"food\", \"clothing\", \"consumable\", \"other\"]\n",
    "\n",
    "### 3.4) Assumptions\n",
    "Since the constraints that can be implemented in Neo4j focus only on the structure and data type, and do not allow constraints on the actual values or the direction of relationships, I assume that whichever software provides the data to be inserted into the database has correctly implemented all the constraints listed above (except for the constraints on the properties `tx_date_...`, since those can be validated at the database level). In our case, we assume that the values produced by the *Transaction Data Simulator* tool are correct and comply with the constraints. \n",
    "\n",
    "Since Neo4j constraints also do not allow us to define the direction of relationships, it is our responsibility to ensure that, in the queries used to create relationships, we do not make mistakes and avoid generating relationships in the wrong direction.\n",
    "\n",
    "For more detailed information, I refer you to the Neo4j [documentation](https://neo4j.com/docs/cypher-manual/current/constraints/managing-constraints/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39af186-d0a2-4bf5-b597-b8f5a350bc51",
   "metadata": {},
   "source": [
    "## 4) Neo4j Data Loading\n",
    "To proceed the following Python packages are required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95383e31-f7c8-4b24-a4e9-0facf81aecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import neo4j\n",
    "import logging\n",
    "logging.getLogger(\"neo4j\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7822175-8e8e-4ac4-93da-66f667091953",
   "metadata": {},
   "source": [
    "To facilitate interactions with Neo4j, we will define some \"kernel\" functions that will be used to interface with the database. These functions will simplify managing data with Neo4j, providing reusable methods for the rest of the project.\n",
    "\n",
    "To keep the code simple and easily understandable, the \"kernel\" functions will be passed queries with parameters embedded directly through string concatenation. While this approach allows for simpler coding, it exposes potential vulnerabilities related to direct parameter concatenation in queries. Since addressing these security concerns is not the goal of this project, but rather demonstrating how the database was managed to optimize workload, I opted to keep the code as straightforward as possible.\n",
    "\n",
    "Before defining the kernel functions, we set some configuration parameters that will be useful not only for the kernel functions themselves but also for the various queries that will be executed later in the project through the kernel functions.\n",
    "Among the configuration parameters, we have:\n",
    "- `customers_csv_link`, `terminals_csv_link`, `transactions_csv_link`: These parameters reference the CSV files generated for the 14MB database. They can either be local file paths or network links. In a dedicated section, we will explain why network links are preferred in this case. Additionally, in the performance analysis section, we will include the database load times for the 50 MB, 100 MB, and 200 MB databases to provide a comprehensive comparison.\n",
    "- `lines_per_commit`: useful for batch operations sent to the database through specific Cypher directives (in our case, we will use APOC). This parameter indicates how many modified or added rows should be processed before committing the data.\n",
    "- `parallel_loading`: useful for the batch operations mentioned in the previous point. This parameter indicates whether the database should perform the batch operations in parallel or sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c58278ee-178d-4b60-b1ff-88abd5045d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config parameters\n",
    "config = {\n",
    "    \"customers_csv_link\":  \"https://www.dropbox.com/scl/fi/ofi4fd99aydhnp30i2spy/customers.csv?rlkey=iqfr9uaty48gc4toxlssqcvf1&st=h3vqznsz&dl=1\",\n",
    "    \"terminals_csv_link\":  \"https://www.dropbox.com/scl/fi/4tt3cyhnpj4q3y49xksrp/terminals.csv?rlkey=1881everw81e38nc0xa2n32ct&st=8eurat39&dl=1\",\n",
    "    \"transactions_csv_link\":  \"https://www.dropbox.com/scl/fi/we51epibb3p98syq67kcq/transactions.csv?rlkey=4bm84xkt9b7rub9rs0u7cough&st=j1xhtfsa&dl=1\",\n",
    "    \"lines_per_commit\": 1000,\n",
    "    \"parallel_loading\": \"true\"\n",
    "}\n",
    "\n",
    "def get_neo4j_connection():\n",
    "    try:\n",
    "        #Using environment variables (recommended): This method securely stores credentials outside the code by using environment variables.\n",
    "        #uri = os.getenv('NEO4J_URI')\n",
    "        #user = os.getenv('NEO4J_USERNAME')\n",
    "        #password = os.getenv('NEO4J_PASSWORD')\n",
    "        \n",
    "        #Using plain strings (not recommended): This method directly includes credentials in the code, which exposes them to potential security risks.\n",
    "        #In this case, to keep things as simple as possible, I will use plain text credentials since they are for a free version of Neo4j.\n",
    "        #You can create it by following this link: https://neo4j.com/product/auradb\n",
    "        uri = \"neo4j+s://45d4bc57.databases.neo4j.io\"\n",
    "        user = \"neo4j\"\n",
    "        password = \"o8mbh0hFGILahScLJw2yTYWIwQ6z7lPhQT6m-U2W1c8\"\n",
    "\n",
    "        #local db\n",
    "        #uri = \"bolt://localhost:7687\"\n",
    "        #user = \"neo4j\"\n",
    "        #password = \"abcdefgh\"\n",
    "\n",
    "        return neo4j.GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: An unexpected error occurred while connecting to Neo4j: {e}\")\n",
    "        return None\n",
    "\n",
    "def close_neo4j_connection(driver):\n",
    "    if driver is not None:\n",
    "        driver.close()\n",
    "\n",
    "def clear_database():\n",
    "    driver = get_neo4j_connection()\n",
    "    delete_nodes_query = \"\"\"\n",
    "        MATCH (n)\n",
    "        CALL apoc.nodes.delete(n, $lines_per_commit) YIELD value\n",
    "        RETURN value\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        with driver.session() as session:\n",
    "            session.run(delete_nodes_query, {\"lines_per_commit\": config[\"lines_per_commit\"]})\n",
    "\n",
    "            constraints_result = session.run(\"SHOW CONSTRAINTS\")\n",
    "            for record in constraints_result:\n",
    "                drop_constraint_query = \"DROP CONSTRAINT $name\"\n",
    "                session.run(drop_constraint_query, {\"name\": record[\"name\"]})\n",
    "\n",
    "            indexes_result = session.run(\"SHOW INDEXES\")\n",
    "            for record in indexes_result:\n",
    "                drop_index_query = \"DROP INDEX $name\"\n",
    "                session.run(drop_index_query, {\"name\": record[\"name\"]})\n",
    "\n",
    "            print(\"clear_database execution time: {:.2f}s\".format(time.time() - start_time))\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR clear_database: {e}\")\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        close_neo4j_connection(driver)\n",
    "\n",
    "def execute_query_commands(name, queries):\n",
    "    driver = get_neo4j_connection()\n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            start_time = time.time()\n",
    "            for query in queries:\n",
    "                try:\n",
    "                    session.run(query)\n",
    "                except Exception as e:\n",
    "                    return False\n",
    "            \n",
    "            print(f\"{name} execution time: {{:.2f}}s\".format(time.time() - start_time))\n",
    "            return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR {name}: {e}\")\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        close_neo4j_connection(driver)\n",
    "\n",
    "def execute_query_df(name, query):\n",
    "    driver = get_neo4j_connection()\n",
    "    if driver is None:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        start_time=time.time()\n",
    "        result = driver.execute_query(query, result_transformer_= neo4j.Result.to_df)\n",
    "        print(f\"{name} execution time: {{:.2f}}s\".format(time.time() - start_time))\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR {name}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        close_neo4j_connection(driver)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098dadb5-4648-420c-b573-ab23124907dc",
   "metadata": {},
   "source": [
    "**Let’s begin by cleaning the database.** This step is unnecessary if you have just created a new database instance, but if you are reusing an instance on which you have already performed some operations, such as running this notebook before, it is advisable to restore it to its original state by clearing everything. In this case, the `clear_database()` function comes to our aid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73ad3ab8-2b74-46dd-a5ae-f02d0092de6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear_database execution time: 3.60s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893ebdd-a7d9-4b76-912e-0923b67c4c4f",
   "metadata": {},
   "source": [
    "### 4.1) Schema\n",
    "Neo4j constraints focus solely on the data structure, as they are used to define a schema for the data. Thanks to Neo4j's schemaless nature, or more generally the schemaless nature of NoSQL databases, it is possible to insert data with maximum flexibility, without the need to define a formal schema in advance. This flexibility allows for handling heterogeneous data and adapting to changes over time, making it ideal for scenarios where the data structure may evolve.\n",
    "\n",
    "However, despite this flexibility, defining a schema is still considered good practice. It provides several benefits, particularly in terms of performance when running queries that filter data or when calculations need to be performed on the data. By enforcing data types and data presence through the schema, the database can optimize certain operations, especially those that involve processing already present values. On the other hand, one drawback of using a schema is that it requires additional processing during insertions and modifications, as the database must validate that each new piece of data complies with the defined constraints.\n",
    "\n",
    "The schema we are about to define in the database involves taking the previously documented logical model and:\n",
    "- adding constraints that associate each attribute with its respective type;\n",
    "- defining, for each entity (from the logical model), the attributes that form the primary key.\n",
    "- Adding constraints that make the attributes mandatory, for attributes not specified as primary keys, since they are already mandatory due to the primary key constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33ffa2bc-6bfb-4fba-a28d-954560379160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_terminals_schema():\n",
    "    queries = [\n",
    "        \"CREATE CONSTRAINT terminal_id_is_integer FOR (t:Terminal) REQUIRE t.terminal_id IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT terminal_id_key FOR (t:Terminal) REQUIRE t.terminal_id IS NODE KEY;\",\n",
    "        \"CREATE CONSTRAINT terminal_x_is_float FOR (t:Terminal) REQUIRE t.x_terminal_id IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT terminal_x_required FOR (t:Terminal) REQUIRE t.x_terminal_id IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT terminal_y_is_float FOR (t:Terminal) REQUIRE t.y_terminal_id IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT terminal_y_required FOR (t:Terminal) REQUIRE t.y_terminal_id IS NOT NULL;\"\n",
    "    ]\n",
    "    \n",
    "    return execute_query_commands(\"create_terminals_schema\", queries)\n",
    "\n",
    "def create_customers_schema():\n",
    "    queries = [\n",
    "        \"CREATE CONSTRAINT customer_id_is_integer FOR (c:Customer) REQUIRE c.customer_id IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT customer_id_key FOR (c:Customer) REQUIRE c.customer_id IS NODE KEY;\",\n",
    "        \"CREATE CONSTRAINT customer_x_is_float FOR (c:Customer) REQUIRE c.x_customer_id IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT customer_x_required FOR (c:Customer) REQUIRE c.x_customer_id IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT customer_y_is_float FOR (c:Customer) REQUIRE c.y_customer_id IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT customer_y_required FOR (c:Customer) REQUIRE c.y_customer_id IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT customer_mean_amount_is_float FOR (c:Customer) REQUIRE c.mean_amount IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT customer_mean_amount_required FOR (c:Customer) REQUIRE c.mean_amount IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT customer_std_amount_is_float FOR (c:Customer) REQUIRE c.std_amount IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT customer_std_amount_required FOR (c:Customer) REQUIRE c.std_amount IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT customer_mean_nb_tx_per_day_is_float FOR (c:Customer) REQUIRE c.mean_nb_tx_per_day IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT customer_mean_nb_tx_per_day_required FOR (c:Customer) REQUIRE c.mean_nb_tx_per_day IS NOT NULL;\"\n",
    "    ]\n",
    "    return execute_query_commands(\"create_customers_schema\", queries)\n",
    "\n",
    "def create_transaction_schema():\n",
    "    queries = [\n",
    "        \"CREATE CONSTRAINT transaction_id_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.transaction_id IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT transaction_id_key FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.transaction_id IS RELATIONSHIP KEY;\",\n",
    "        \"CREATE CONSTRAINT tx_time_seconds_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_time_seconds IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_time_seconds_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_time_seconds IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_time_days_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_time_days IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_time_days_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_time_days IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_amount_is_float FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_amount IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT tx_amount_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_amount IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_date_day_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_day IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_date_day_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_day IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_date_month_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_month IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_date_month_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_month IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_date_year_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_year IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_date_year_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_year IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_date_time_is_localtime FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_time IS :: LOCAL TIME;\",\n",
    "        \"CREATE CONSTRAINT tx_date_time_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_time IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_fraud_is_boolean FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_fraud IS :: BOOLEAN;\",\n",
    "        \"CREATE CONSTRAINT tx_fraud_is_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_fraud IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_fraud_scenario_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_fraud_scenario IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_fraud_scenario_is_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_fraud_scenario IS NOT NULL;\"\n",
    "    ]\n",
    "    return execute_query_commands(\"create_transaction_schema\", queries)\n",
    "\n",
    "create_terminals_schema()\n",
    "create_customers_schema()\n",
    "create_transaction_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8776b-b0f4-490f-a03e-747dbd8cc818",
   "metadata": {},
   "source": [
    "### 4.2) Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a230cf7a-cfbc-4387-9f0d-e02f4f9cb736",
   "metadata": {},
   "source": [
    "To load data into Neo4j using CSV files, we must first consider where the Neo4j instance resides in which we want to load the data. This aspect is crucial because the CSV files must be accessible from the machine running the Neo4j instance. This results in two possible scenarios:\n",
    "- The CSV files reside on the machine where the Neo4j instance is running,\n",
    "- The CSV files are network resources that can be directly downloaded via a link.\n",
    "\n",
    "Since we are using a Neo4j instance managed by an external company, Aura, they obviously do not provide us access to their servers, so we must opt for the second option.\n",
    "\n",
    "This will have an impact on the data loading performance, as the time indicated by the loading procedure will not only account for the time required to load the data from the file to the database but will also include the time for the Neo4j instance to download the file. The download time is not negligible because, as we know, the network is much slower compared to a completely local approach. Check it yourself by pasting the transactions CSV file URL into your browser and seeing how long it takes for your machine to download the file.\n",
    "\n",
    "It’s important to use a direct download link for the CSV files to ensure everything works. For easily and quickly sharing these files, I chose Dropbox because it offers a file sharing option with links that include a query parameter in the URL. This parameter, appearing as `&dl=1` at the end of the link, allows me to specify whether the link should be a direct download. This feature is crucial for the Neo4j instance to download the file correctly. I also explored other cloud storage systems, but the process of obtaining a direct download link was unnecessarily more complex.\n",
    "\n",
    "Now let's look at the queries used to load the data into the database. Initially, I considered loading the data using the same example provided by the professor during the lessons `USING PERIODIC COMMIT 1000 LOAD CSV FROM ...`, used to load data from a CSV file in batches of N rows per commit. However, since this directive has been deprecated, I opted for `LOAD CSV WITH HEADERS FROM ... CALL {...} IN TRANSACTIONS OF 1000 ROWS`, which allowed me to achieve the same behavior.\n",
    "\n",
    "All three functions work similarly, with only the modifications they make to the database changing. Each function downloads the CSV file specified via the link and then starts with the batch job inside the `CALL{}` statement where the query creates the data instances in the database. At the end of the query in the `IN TRANSACTIONS OF 1000 ROWS` statement we spacify how many rows from the CSV to process before committing the changes to the database.\n",
    "\n",
    "In all 3 queries the instances are created with a `MERGE` statement, which sets the properties of the instance using the `ON CREATE SET` clause.\n",
    "- The function `load_customers_with_available_terminals_from_csv()` not only creates the customer but also opens the list of terminals on which the customer can operate, matches them, and creates an `Available` relationship between the customer and all the matched terminals.\n",
    "  \n",
    "- The function `load_transactions_from_csv()`, before creating the transaction as described earlier, must match the customer and terminal for the relationship creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d33bb27-1736-4e1a-aa16-b2e7d459dd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_terminals_from_csv execution time: 1.61s\n",
      "load_customers_with_available_terminals_from_csv execution time: 1.93s\n",
      "load_transactions_from_csv execution time: 25.88s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def load_terminals_from_csv():\n",
    "    query = f\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"{config[\"terminals_csv_link\"]}\" AS row FIELDTERMINATOR ';'\n",
    "        CALL {{\n",
    "            WITH row\n",
    "            CREATE (:Terminal {{terminal_id: toInteger(row.TERMINAL_ID),\n",
    "                                x_terminal_id: toFloat(row.x_terminal_id),\n",
    "                                y_terminal_id: toFloat(row.y_terminal_id)}})\n",
    "        }} IN TRANSACTIONS OF {config[\"lines_per_commit\"]} ROWS\n",
    "    \"\"\"\n",
    "    return execute_query_commands(\"load_terminals_from_csv\", [query])\n",
    "\n",
    "def load_customers_with_available_terminals_from_csv():    \n",
    "    query = f\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"{config[\"customers_csv_link\"]}\" AS row FIELDTERMINATOR \";\" \n",
    "        CALL {{\n",
    "            WITH row\n",
    "            MERGE (c:Customer {{customer_id: toInteger(row.CUSTOMER_ID)}})\n",
    "            ON CREATE SET  \n",
    "                c.x_customer_id = toFloat(row.x_customer_id),\n",
    "                c.y_customer_id = toFloat(row.y_customer_id),\n",
    "                c.mean_amount = toFloat(row.mean_amount),\n",
    "                c.std_amount = toFloat(row.std_amount),\n",
    "                c.mean_nb_tx_per_day = toFloat(row.mean_nb_tx_per_day)\n",
    "            WITH c, row\n",
    "            WITH c, apoc.convert.fromJsonList(row.available_terminals) AS available_terminal_ids\n",
    "            UNWIND available_terminal_ids AS available_terminal_id\n",
    "            MATCH (t:Terminal {{terminal_id: available_terminal_id}})\n",
    "            MERGE (c)-[:Available]->(t)\n",
    "        }} IN TRANSACTIONS OF {config[\"lines_per_commit\"]} ROWS\n",
    "    \"\"\"\n",
    "\n",
    "    return execute_query_commands(\"load_customers_with_available_terminals_from_csv\", [query])\n",
    "\n",
    "def load_transactions_from_csv():\n",
    "    query = f\"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM \"{config[\"transactions_csv_link\"]}\" AS row FIELDTERMINATOR \";\" \n",
    "        CALL{{\n",
    "            WITH row\n",
    "\n",
    "            WITH row, \n",
    "                 split(row.TX_DATETIME, \" \") AS splitted_date_time\n",
    "            \n",
    "            WITH row,\n",
    "                 date(splitted_date_time[0]) AS parsed_date,\n",
    "                 localtime(splitted_date_time[1]) AS parsed_local_time\n",
    "\n",
    "            MATCH (c:Customer {{customer_id: toInteger(row.CUSTOMER_ID)}}), \n",
    "                (t:Terminal {{terminal_id: toInteger(row.TERMINAL_ID)}})\n",
    "            MERGE (c)-[transaction:Make_transaction {{transaction_id: toInteger(row.TRANSACTION_ID)}}]->(t)\n",
    "            ON CREATE SET \n",
    "                transaction.tx_time_seconds = toInteger(row.TX_TIME_SECONDS), \n",
    "                transaction.tx_time_days = toInteger(row.TX_TIME_DAYS),\n",
    "                transaction.tx_amount = toFloat(row.TX_AMOUNT), \n",
    "                transaction.tx_fraud = toBoolean(toInteger(row.TX_FRAUD)), \n",
    "                transaction.tx_fraud_scenario = toInteger(row.TX_FRAUD_SCENARIO),\n",
    "\n",
    "                transaction.tx_date_day = parsed_date.day,\n",
    "                transaction.tx_date_month = parsed_date.month,\n",
    "                transaction.tx_date_year = parsed_date.year, \n",
    "                transaction.tx_date_time = parsed_local_time \n",
    "        }} IN TRANSACTIONS OF {config[\"lines_per_commit\"]} ROWS\n",
    "    \"\"\"\n",
    "    return execute_query_commands(\"load_transactions_from_csv\", [query])\n",
    "\n",
    "\n",
    "load_terminals_from_csv()\n",
    "load_customers_with_available_terminals_from_csv()\n",
    "load_transactions_from_csv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ffc76c-18c7-4ddd-a0b5-749390db5388",
   "metadata": {},
   "source": [
    "## 5) Workload\n",
    "In this section, I’ll explain how I implemented the queries to efficiently respond to the various requests outlined in the project specifications. Since the requested queries were not always precise in every detail, each query’s analysis will follow these key points:\n",
    "- Report the query as expressed in the project specifications.\n",
    "- Explain my interpretation of the query.\n",
    "- Explain how i have built the query, providing the query code\n",
    "- Look at the results\n",
    "- Evaluate the query's performance. Where necessary, to demonstrate the optimizations I have added, the execution plan will also be provided.\n",
    "\n",
    "Others queries performance details will be included in the dedicated section, where the execution times of the various queries will be compared across databases of different sizes.\n",
    "\n",
    "**An important note:** Since I couldn’t find a way to clear the caches in the free Neo4j instance (and I don’t believe it’s possible), when comparing the execution times of different versions of the same query or the same query on different databases, it’s crucial to ensure the accuracy of the timings by running them multiple times. For queries that modify the database state, such as those that create schema, insert data, or modify existing data, they should be executed at most once per clean database instance. To re-run them, it’s necessary to restart the instance by using the `clear_database()` function. This is because the schema-creating functions are designed to fail if a schema rule already exists, ensuring that you are not using an unclean instance. The only exception to the rule for queries that modify the database state and can be re-run as many times as needed is `create_composite_index_if_not_exists_on_Make_transaction_tx_date_month_and_tx_date_year()`. This query builds an index to optimize queries. If an index with the same name already exists, the function does nothing and does not create a new one. If the existing index does not match the one defined by the function, it will not be critical to the database, but the queries may not be optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e41734-85e9-4fe2-be18-43cadd3afe18",
   "metadata": {},
   "source": [
    "### 5.1) Query A\n",
    "#### 5.1.1) Query request\n",
    "> For each customer checks that the spending frequency and the spending amounts of the last month is under the usual spending frequency and the spending amounts for the same period.\n",
    "\n",
    "- \"for each customer\": this indicates that the query results must include all customers, even those for whom it is not possible to calculate the requested data.  \n",
    "\n",
    "- \"of the last month\": refers to the month preceding the one provided as a parameter in the query. To call the python function that executes this query you have to specify partial date in the \"yyyy-MM\" format as a parameter. This date is then used to calculate the `first_of_previous_month` variable within the query. This variable represents the first day of the month immediately prior to the given date. When determining the value of `first_of_previous_month`, only the month and year are considered, ensuring that the query correctly filters data relevant to the previous month.  \n",
    "\n",
    "- \"usual spending frequency and the spending amounts for the same period\": I interpreted this to mean that the spending frequency and spending amount must be calculated as the average of all spending frequencies and amounts recorded in the database that match the same month but correspond to a year earlier than the `first_of_previous_month` variable.\n",
    "\n",
    "#### 5.1.2) A1 query code\n",
    "Let's provide a first version of the query A\n",
    "\n",
    "The query starts by calculating the date corresponding to the first day of the previous month relative to the date provided to the Python function. This date is saved in the variable `first_of_previous_month`.\n",
    "\n",
    "Next, all customers are matched to ensure that none are excluded from the final result of the query. This is done because the following `WHERE` clauses do not filter out customers, and all subsequent matches are `OPTIONAL MATCH`.\n",
    "\n",
    "The first `OPTIONAL MATCH` is used to retrieve the transaction history for the same period, this transactions are stored in the variable `tx_prev_month_all_prev_year`.\n",
    "\n",
    "The subsequent `WITH` clause is particular because, instead of counting the `tx_prev_month_all_prev_year` and summing their amounts, it returns `NULL` for both values, if no transactions are found in the history. This is useful for differentiating, in the final result, customers for whom no significant transaction history is found (and therefore no calculations can be made) from those for whom a history is available (and calculations can proceed as required by the query).\n",
    "\n",
    "The next `WITH` clause calculates the averages of the just computed results `tx_prev_month_prev_year_total_amount` and `tx_prev_month_prev_year_montly_freq` obtaining  `tx_prev_month_all_prev_year_total_amount_avg` and `tx_prev_month_all_prev_year_montly_freq_avg`. The `AVG` operator preserves the `NULL` value when calculating based on `NULL`; thus, if there are no transactions, `AVG(NULL)` will return `NULL`.\n",
    "\n",
    "The last `OPTIONAL MATCH` performs the same calculations as the previous one, but now on transactions `tx` that have same month and year as `first_of_previous_month`. Unlike before, distinguishing between customers with and without transactions is not required at this stage, as this distinction will be handled in the `RETURN` clause by referencing the historical data.\n",
    "\n",
    "The last `WITH` calculates `total_amount_prev_month` and `monthly_freq_prev_month`, which represent the total transactions amount and transaction frequency of all the `tx`s. These two values are then used in the `RETURN` stage to determine if they fall below the usual average transactions amounts and frequency.\n",
    "\n",
    "In the `RETURN` statement, if the customer has historical data for the same period (indicated by `tx_prev_month_all_prev_year_monthly_freq_avg IS NOT NULL`), we proceed to check whether `total_amount_prev_month < tx_prev_month_all_prev_year_total_amount_avg` and `monthly_freq_prev_month < tx_prev_month_all_prev_year_monthly_freq_avg`. It is important to note that, in this scenario, the customer may not have any `tx`s. However, since historical data is available, the absence of `tx`s does not indicate missing data in the database. Instead, it signifies that the customer did not perform any transactions during the same month and year as `first_of_previous_month`.\n",
    "\n",
    "If a customer hasn't the same period historical data we cannot provide any meaningful response so we repond with `NULL` value in both column `is_under_total_amount_avg_of_same_period` and `is_under_monthly_freq_avg_of_same_period`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d7b78d7-88dd-47ef-8320-94f6655c6984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_a1 execution time: 6.02s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>is_under_total_amount_avg_of_same_period</th>\n",
       "      <th>is_under_monthly_freq_avg_of_same_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     c  \\\n",
       "0    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "1    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "2    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "3    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "4    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "..                                                 ...   \n",
       "195  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "196  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "197  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "198  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "199  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "\n",
       "    is_under_total_amount_avg_of_same_period  \\\n",
       "0                                      False   \n",
       "1                                       True   \n",
       "2                                       None   \n",
       "3                                      False   \n",
       "4                                       None   \n",
       "..                                       ...   \n",
       "195                                    False   \n",
       "196                                     None   \n",
       "197                                     None   \n",
       "198                                     True   \n",
       "199                                     True   \n",
       "\n",
       "    is_under_monthly_freq_avg_of_same_period  \n",
       "0                                      False  \n",
       "1                                       True  \n",
       "2                                       None  \n",
       "3                                      False  \n",
       "4                                       None  \n",
       "..                                       ...  \n",
       "195                                     True  \n",
       "196                                     None  \n",
       "197                                     None  \n",
       "198                                     True  \n",
       "199                                     True  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#year_and_month_under_analesis is a string that contains a year and a month in the format yyyy-MM\n",
    "def query_a1(year_and_month_under_analesis):\n",
    "    query = f\"\"\"\n",
    "            WITH date.truncate('month', date(\"{year_and_month_under_analesis}\" + \"-01\") ) - duration({{months: 1}}) AS first_of_previous_month\n",
    "            \n",
    "            MATCH (c:Customer)\n",
    "\n",
    "            OPTIONAL MATCH (c)-[tx_prev_month_all_prev_year:Make_transaction]->(:Terminal)\n",
    "            WHERE \n",
    "                tx_prev_month_all_prev_year.tx_date_month = first_of_previous_month.month\n",
    "                AND tx_prev_month_all_prev_year.tx_date_year < first_of_previous_month.year\n",
    "            WITH\n",
    "                first_of_previous_month,\n",
    "                c,\n",
    "                tx_prev_month_all_prev_year.tx_date_year as year, \n",
    "                CASE \n",
    "                    WHEN COUNT(tx_prev_month_all_prev_year)>0 THEN SUM(tx_prev_month_all_prev_year.tx_amount)\n",
    "                    ELSE NULL\n",
    "                END AS tx_prev_month_prev_year_total_amount, \n",
    "\n",
    "                CASE \n",
    "                    WHEN  COUNT(tx_prev_month_all_prev_year)>0 THEN COUNT(tx_prev_month_all_prev_year)\n",
    "                    ELSE NULL\n",
    "                END AS tx_prev_month_prev_year_montly_freq\n",
    "            WITH\n",
    "            first_of_previous_month,\n",
    "            c, \n",
    "            AVG(tx_prev_month_prev_year_total_amount) AS tx_prev_month_all_prev_year_total_amount_avg, \n",
    "            AVG(tx_prev_month_prev_year_montly_freq) AS tx_prev_month_all_prev_year_montly_freq_avg\n",
    "\n",
    "            OPTIONAL MATCH (c)-[tx:Make_transaction]->(:Terminal)\n",
    "            WHERE \n",
    "                tx.tx_date_month = first_of_previous_month.month AND \n",
    "                tx.tx_date_year = first_of_previous_month.year\n",
    "            WITH\n",
    "                c,\n",
    "                SUM(tx.tx_amount) AS total_amount_prev_month, \n",
    "                COUNT(tx) AS monthly_freq_prev_month,\n",
    "                tx_prev_month_all_prev_year_total_amount_avg,\n",
    "                tx_prev_month_all_prev_year_montly_freq_avg\n",
    "\n",
    "            RETURN\n",
    "                c,\n",
    "\n",
    "                CASE \n",
    "                    WHEN tx_prev_month_all_prev_year_total_amount_avg IS NULL THEN NULL\n",
    "                    ELSE total_amount_prev_month < tx_prev_month_all_prev_year_total_amount_avg\n",
    "                END AS is_under_total_amount_avg_of_same_period,\n",
    "\n",
    "                CASE \n",
    "                    WHEN tx_prev_month_all_prev_year_montly_freq_avg IS NULL THEN NULL\n",
    "                    ELSE monthly_freq_prev_month < tx_prev_month_all_prev_year_montly_freq_avg\n",
    "                END AS is_under_monthly_freq_avg_of_same_period\n",
    "    \"\"\"\n",
    "\n",
    "    return execute_query_df(\"query_a1\",query)\n",
    "\n",
    "month_and_year_under_analesis = \"2023-05\"\n",
    "query_a1(month_and_year_under_analesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa63752-1b6a-45d7-a369-d4105a3b2af5",
   "metadata": {},
   "source": [
    "#### 5.1.3) A1 Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c1145-46af-42c6-bc35-746eaf941ddc",
   "metadata": {},
   "source": [
    "To improve the query performance since it fiters the data on `make_transaction.tx_date_month` and `make_transaction.tx_date_year` we can build a compound index on these two fiels\n",
    "after that we can call again the query passing the same argument and look at the execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5beb648-9448-4bcd-a68e-3691b213d87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_composite_index_if_not_exists_on_Make_transaction_tx_date_month_and_tx_date_year execution time: 0.61s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_composite_index_if_not_exists_on_Make_transaction_tx_date_month_and_tx_date_year():\n",
    "    query = \"CREATE INDEX composite_index_on_tx_date_year_and_month IF NOT EXISTS FOR ()-[tx:Make_transaction]-() ON (tx.tx_date_month, tx.tx_date_year)\"\n",
    "    return execute_query_commands(\"create_composite_index_if_not_exists_on_Make_transaction_tx_date_month_and_tx_date_year\", [query])\n",
    "\n",
    "create_composite_index_if_not_exists_on_Make_transaction_tx_date_month_and_tx_date_year()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e77c988-6f70-4ad0-a490-1d7cc91ae759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_a1 execution time: 3.24s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>is_under_total_amount_avg_of_same_period</th>\n",
       "      <th>is_under_monthly_freq_avg_of_same_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     c  \\\n",
       "0    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "1    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "2    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "3    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "4    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "..                                                 ...   \n",
       "195  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "196  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "197  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "198  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "199  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "\n",
       "    is_under_total_amount_avg_of_same_period  \\\n",
       "0                                      False   \n",
       "1                                       True   \n",
       "2                                       None   \n",
       "3                                      False   \n",
       "4                                       None   \n",
       "..                                       ...   \n",
       "195                                    False   \n",
       "196                                     None   \n",
       "197                                     None   \n",
       "198                                     True   \n",
       "199                                     True   \n",
       "\n",
       "    is_under_monthly_freq_avg_of_same_period  \n",
       "0                                      False  \n",
       "1                                       True  \n",
       "2                                       None  \n",
       "3                                      False  \n",
       "4                                       None  \n",
       "..                                       ...  \n",
       "195                                     True  \n",
       "196                                     None  \n",
       "197                                     None  \n",
       "198                                     True  \n",
       "199                                     True  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_a1(month_and_year_under_analesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9086f3-1741-45ca-9f8d-3b9b35428042",
   "metadata": {},
   "source": [
    "As shown in the execution plan image below, the query is not utilizing the index at all! This occurs because, in the initial `MATCH` clause, we are not directly filtering the transactions. Instead, we first match the customers, which prevents the query from leveraging the index efficiently.  \n",
    "\n",
    "In fact, the only index used is on the customers, and it is applied merely to retrieve all customer nodes without performing any filtering. Regarding transactions, no index is utilized either in the initial filtering or in the subsequent `OPTIONAL MATCH`, further contributing to the inefficiency of the query.  \n",
    "\n",
    "To generate the execution plan shown in the image, you simply need to prefix the query with the word `EXPLAIN` in Neo4j.  \n",
    "\n",
    "<img src=\"./assets/Execution plan query A1.svg\" style=\"width:600px;\">\n",
    "\n",
    "#### 5.1.4) A2 query code\n",
    "By slightly modifying the query to omit the \"for all customers\" clause and displaying only customers with historical data, we can significantly improve performance by leveraging the index. This optimization involves removing the initial `MATCH` clause, turning the second `OPTIONAL MATCH` into a regular `MATCH`.  \n",
    "\n",
    "This change means that the results will no longer include customers with `NULL` values in columns `tx_prev_month_all_prev_year_total_amount_avg` and `tx_prev_month_all_prev_year_montly_freq_avg`, as these customers will be excluded directly by the first `MATCH` clause.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e1ba842-727c-41a5-9d17-4e09cd7f9606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_a2 execution time: 2.03s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>is_under_total_amount_avg_of_same_period</th>\n",
       "      <th>is_under_monthly_freq_avg_of_same_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     c  \\\n",
       "0    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "1    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "2    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "3    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "4    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "..                                                 ...   \n",
       "103  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "104  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "105  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "106  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "107  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "\n",
       "     is_under_total_amount_avg_of_same_period  \\\n",
       "0                                       False   \n",
       "1                                       False   \n",
       "2                                        True   \n",
       "3                                        True   \n",
       "4                                       False   \n",
       "..                                        ...   \n",
       "103                                     False   \n",
       "104                                     False   \n",
       "105                                     False   \n",
       "106                                      True   \n",
       "107                                     False   \n",
       "\n",
       "     is_under_monthly_freq_avg_of_same_period  \n",
       "0                                        True  \n",
       "1                                        True  \n",
       "2                                       False  \n",
       "3                                       False  \n",
       "4                                       False  \n",
       "..                                        ...  \n",
       "103                                     False  \n",
       "104                                     False  \n",
       "105                                      True  \n",
       "106                                     False  \n",
       "107                                     False  \n",
       "\n",
       "[108 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#year_and_month_under_analesis is a string that contains a year and a month in the format yyyy-MM\n",
    "def query_a2(year_and_month_under_analesis):\n",
    "    query = f\"\"\"\n",
    "            WITH date.truncate('month', date(\"{year_and_month_under_analesis}\" + \"-01\") ) - duration({{months: 1}}) AS first_of_previous_month\n",
    "\n",
    "            MATCH (c)-[tx_prev_month_all_prev_year:Make_transaction]->(:Terminal)\n",
    "            WHERE \n",
    "                tx_prev_month_all_prev_year.tx_date_month = first_of_previous_month.month\n",
    "                AND tx_prev_month_all_prev_year.tx_date_year < first_of_previous_month.year\n",
    "            WITH\n",
    "                first_of_previous_month,\n",
    "                c,\n",
    "                tx_prev_month_all_prev_year.tx_date_year as year,\n",
    "                SUM(tx_prev_month_all_prev_year.tx_amount)  AS tx_prev_month_prev_year_total_amount, \n",
    "                COUNT(tx_prev_month_all_prev_year) AS tx_prev_month_prev_year_montly_freq\n",
    "            WITH\n",
    "            first_of_previous_month,\n",
    "            c, \n",
    "            AVG(tx_prev_month_prev_year_total_amount) AS tx_prev_month_all_prev_year_total_amount_avg, \n",
    "            AVG(tx_prev_month_prev_year_montly_freq) AS tx_prev_month_all_prev_year_montly_freq_avg\n",
    "\n",
    "            OPTIONAL MATCH (c)-[tx:Make_transaction]->(:Terminal)\n",
    "            WHERE \n",
    "                tx.tx_date_month = first_of_previous_month.month AND \n",
    "                tx.tx_date_year = first_of_previous_month.year\n",
    "            WITH\n",
    "                c,\n",
    "                SUM(tx.tx_amount) AS total_amount_prev_month, \n",
    "                COUNT(tx) AS monthly_freq_prev_month,\n",
    "                tx_prev_month_all_prev_year_total_amount_avg,\n",
    "                tx_prev_month_all_prev_year_montly_freq_avg\n",
    "\n",
    "            RETURN\n",
    "                c, \n",
    "                total_amount_prev_month < tx_prev_month_all_prev_year_total_amount_avg  AS is_under_total_amount_avg_of_same_period,\n",
    "                monthly_freq_prev_month < tx_prev_month_all_prev_year_montly_freq_avg AS is_under_monthly_freq_avg_of_same_period\n",
    "            \"\"\"\n",
    "    \n",
    "    return execute_query_df(\"query_a2\",query)\n",
    "query_a2(month_and_year_under_analesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476082d2-7dc3-46ba-a145-4ddb99a62de7",
   "metadata": {},
   "source": [
    "#### 5.1.5) A2 Performances\n",
    "As shown in the execution plan image below, the query is now utilizing the index we specifically created for filtering transactions. Unlike the initial version, where no index was used on the transactions, this optimized approach ensures that the query leverages the index effectively to improve performance during the filtering process.\n",
    "\n",
    "<img src=\"./assets/Execution plan query A2.svg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ad3fc2-d9ea-4d44-a734-6ab076d36be7",
   "metadata": {},
   "source": [
    "### 5.2) Query B\n",
    "#### 5.2.1) Query request\n",
    "> For each terminal identify the possible fraudulent transactions. The fraudulent transactions are those whose import is higher than 20% of the maximal import of the transactions executed on the same terminal in the last month.\n",
    "\n",
    "- \"For each terminal\": This indicates that the query results must include all terminals, even those for which it is not possible to identify any fraudulent transactions.\n",
    "\n",
    "- \"In the last month\": refers to data from the month preceding the one provided as a parameter. Similar to the previous query, this query is also parameterized by allowing a partial date in the \"yyyy-MM\" format to be passed to the python. This date is used to calculate the `first_of_previous_month` variable, which represents the first day of the month prior to the given date. Additionally, the query includes a reference to the first day of the current month, stored in the `today` variable, for further calculations or filtering as needed. \n",
    "\n",
    "#### 5.1.2) B1 Query Code\n",
    "The query begins by saving the provided date into the today variable and computing the first day of the previous month, which is stored in `first_of_previous_month`. \n",
    "\n",
    "Next, all terminals are matched to ensure that none are excluded from the final result of the query. This is done because the following `WHERE` clauses do not filter out terminals, and all subsequent matches are `OPTIONAL MATCH`.\n",
    "\n",
    "The first `OPTIONAL MATCH` retrieves transactions made on terminals during the month and year corresponding to `first_of_previous_month`. These transactions are saved in the `tx_prev_month` variable. However, some terminals may not have any transactions for the specified period, and in those cases, `tx_prev_month` will remain empty for those terminals.\n",
    "\n",
    "Following this, the query calculates the fraud detection threshold using a `WITH` statement. The fraud amount limit, stored in the variable `tx_amount_fraud_limit`, is defined as 20% more than the maximum transaction amount from the previous month. For terminals where no transactions were found in `tx_prev_month`, the fraud amount limit remains `NULL`.\n",
    "\n",
    "The next step uses another `OPTIONAL MATCH` to retrieve transactions for the current month, filtering by the same month and year as `today`. These transactions are stored in the `tx_current_month` variable. Using the calculated fraud amount limit, the query identifies fraudulent transactions by collecting those in `tx_current_month` where the transaction amount exceeds `tx_amount_fraud_limit`. This collection is saved in `fraud_txs_current_month`. If `tx_amount_fraud_limit` is `NULL`, the condition will always evaluate to false, resulting in an empty collection for the terminal.\n",
    "\n",
    "Finally, the `RETURN` statement distinguishes between two problematic cases when a terminal has an empty `fraud_txs_current_month` collection. In the first case, the fraud amount limit could not be calculated, making it impossible to determine whether the terminal had fraudulent transactions. In the second case, the limit was calculated, but no fraudulent transactions were identified for that terminal in the current month. To address this ambiguity, the query replaces empty collections in `fraud_txs_current_month` with the value `NULL` whenever `tx_amount_fraud_limit IS NULL`. This approach ensures clarity in the results, differentiating between the two scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31f3bfcc-2c64-4640-b515-3d3d9346c817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_b1 execution time: 2.82s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>fraud_txs_current_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[(transaction_id, tx_date_year, tx_time_days, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[(transaction_id, tx_date_year, tx_time_days, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[(transaction_id, tx_date_year, tx_time_days, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              t  \\\n",
       "0   (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "1   (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "2   (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "3   (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "4   (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "..                                          ...   \n",
       "95  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "96  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "97  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "98  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "99  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "\n",
       "                              fraud_txs_current_month  \n",
       "0                                                None  \n",
       "1                                                None  \n",
       "2   [(transaction_id, tx_date_year, tx_time_days, ...  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "..                                                ...  \n",
       "95                                                 []  \n",
       "96  [(transaction_id, tx_date_year, tx_time_days, ...  \n",
       "97                                                 []  \n",
       "98                                               None  \n",
       "99  [(transaction_id, tx_date_year, tx_time_days, ...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#year_and_month_under_analesis is a string that contains a year and a month in the format yyyy-MM\n",
    "def query_b1(year_and_month_under_analesis):\n",
    "    query = f\"\"\"\n",
    "            WITH date(\"{year_and_month_under_analesis}\" + \"-01\") AS today\n",
    "            WITH today, date.truncate('month', today ) - duration({{months: 1}}) AS first_of_previous_month\n",
    "\n",
    "            MATCH (t:Terminal)\n",
    "\n",
    "            OPTIONAL MATCH (:Customer)-[tx_prev_month:Make_transaction]->(t)\n",
    "            WHERE \n",
    "                tx_prev_month.tx_date_month = first_of_previous_month.month\n",
    "                AND tx_prev_month.tx_date_year = first_of_previous_month.year\n",
    "\n",
    "            with today, t, max(tx_prev_month.tx_amount) * 1.2 as tx_amount_fraud_limit\n",
    "\n",
    "            OPTIONAL MATCH (:Customer)-[tx_current_month:Make_transaction]->(t)\n",
    "            WHERE \n",
    "                tx_current_month.tx_date_month = today.month\n",
    "                AND tx_current_month.tx_date_year = today.year\n",
    "\n",
    "            WITH \n",
    "                t, \n",
    "                tx_amount_fraud_limit,\n",
    "                COLLECT(CASE \n",
    "                    WHEN tx_current_month.tx_amount > tx_amount_fraud_limit THEN tx_current_month \n",
    "                    ELSE NULL \n",
    "                END) AS fraud_txs_current_month\n",
    "\n",
    "            RETURN \n",
    "                t, \n",
    "                CASE \n",
    "                    WHEN tx_amount_fraud_limit IS NULL THEN NULL\n",
    "                    ELSE fraud_txs_current_month\n",
    "                END AS fraud_txs_current_month\n",
    "            \"\"\"\n",
    "\n",
    "    return execute_query_df(\"query_b1\",query)\n",
    "query_b1(month_and_year_under_analesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e54644-ad05-4920-a6a5-8816e6aa4e1c",
   "metadata": {},
   "source": [
    "#### 5.1.3) B1 Performances\n",
    "To improve the query performance since it fiters the data on `make_transaction.tx_date_month` and `make_transaction.tx_date_year` we can reuse the compound index previously created with the python function `create_composite_index_if_not_exists_on_Make_transaction_tx_date_month_and_tx_date_year()`\n",
    "\n",
    "As we can see in the execution plan of the query shown below, the same behavior observed in the previous query occurs here as well. Specifically, the first `MATCH` clause, which matches all terminals, prevents the index from being used to filter the transactions.  \n",
    "\n",
    "In fact, the only index used is on the terminals, and it is applied merely to retrieve all terminals nodes without performing any filtering. Regarding transactions, no index is utilized either in the initial filtering or in the subsequent `OPTIONAL MATCH`, further contributing to the inefficiency of the query.  \n",
    "\n",
    "<img src=\"./assets/Execution plan query B1.svg\" style=\"width:600px;\">\n",
    "\n",
    "#### 5.1.4) B2 Query code\n",
    "By slightly modifying the query to omit the \"for all terminals\" clause and displaying only terminals with `tx_amount_fraud_limit`, we can improve performance by leveraging the index. This optimization involves removing the initial `MATCH` clause, turning the second `OPTIONAL MATCH` into a regular `MATCH`.  \n",
    "\n",
    "This change means that the results will no longer include terminals with `NULL` values in the `fraud_txs_current_month` column as these terminals will be excluded directly by the first `MATCH` clause.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "849393fa-5315-41f2-a1d3-c30684ab45ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_b2 execution time: 1.93s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>fraud_txs_current_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[(transaction_id, tx_date_year, tx_time_days, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              t  \\\n",
       "0   (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "1   (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "2   (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "3   (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "4   (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "..                                          ...   \n",
       "73  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "74  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "75  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "76  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "77  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "\n",
       "                              fraud_txs_current_month  \n",
       "0                                                  []  \n",
       "1                                                  []  \n",
       "2                                                  []  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "..                                                ...  \n",
       "73                                                 []  \n",
       "74  [(transaction_id, tx_date_year, tx_time_days, ...  \n",
       "75                                                 []  \n",
       "76                                                 []  \n",
       "77                                                 []  \n",
       "\n",
       "[78 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#year_and_month_under_analesis is a string that contains a year and a month in the format yyyy-MM\n",
    "def query_b2(year_and_month_under_analesis):\n",
    "    query = f\"\"\"\n",
    "            WITH date(\"{year_and_month_under_analesis}\" + \"-01\") AS today\n",
    "            WITH today, date.truncate('month', today ) - duration({{months: 1}}) AS first_of_previous_month\n",
    "\n",
    "            MATCH (:Customer)-[tx_prev_month:Make_transaction]->(t:Terminal)\n",
    "            WHERE \n",
    "                tx_prev_month.tx_date_month = first_of_previous_month.month\n",
    "                AND tx_prev_month.tx_date_year = first_of_previous_month.year\n",
    "\n",
    "            with today, t, max(tx_prev_month.tx_amount) * 1.2 as tx_amount_fraud_limit\n",
    "\n",
    "            OPTIONAL MATCH (:Customer)-[tx_current_month:Make_transaction]->(t)\n",
    "            WHERE \n",
    "                tx_current_month.tx_date_month = today.month\n",
    "                AND tx_current_month.tx_date_year = today.year\n",
    "\n",
    "            RETURN \n",
    "                t,\n",
    "                COLLECT( \n",
    "                    CASE \n",
    "                        WHEN tx_current_month.tx_amount > tx_amount_fraud_limit THEN tx_current_month \n",
    "                        ELSE NULL \n",
    "                    END \n",
    "                )AS fraud_txs_current_month\n",
    "            \"\"\"\n",
    "   \n",
    "    return execute_query_df(\"query_b2\",query)\n",
    "query_b2(month_and_year_under_analesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228735b7-22b4-47c0-9997-f4cc0ce70bcb",
   "metadata": {},
   "source": [
    "#### 5.1.4) B2 Performances\n",
    "As shown in the execution plan image below, the query is now utilizing the index we specifically created for filtering transactions. Unlike the initial version, where no index was used on the transactions, this optimized approach ensures that the query leverages the index effectively to improve performance during the filtering process.\n",
    "\n",
    "<img src=\"./assets/Execution plan query B2.svg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f7927-bb15-46bd-a42c-1bd31bd9152b",
   "metadata": {},
   "source": [
    "### 5.3) Query C\n",
    "#### 5.3.1) Query request\n",
    "> Given a user u, determine the “co-customer-relationships CC of degree k”. A user u’ is a co-customer of u if you can determine a chain “u1-t1-u2-t2-…tk-1-uk“ such that u1=u, uk=u’, and for each 1<=I,j<=k, ui <> uj, and t1,..tk-1 are the terminals on which a transaction has been\n",
    "executed. Therefore, CCk(u)={u’| a chain exists between u and u’ of degree k}. Please, note that depending on the adopted model, the computation of CCk(u) could be quite complicated. Consider therefore at least the computation of CC3(u) (i.e. the co-costumer relationships of degree 3).\n",
    "\n",
    "This request is very precise and does not require any further elaboration. What I would like to emphasize is the proposed solution that utilizes an APOC function for efficient graph traversal. This approach will prove to be highly efficient, enabling us to surpass the co-customer of degree `k` in remarkably short processing times.\n",
    "\n",
    "#### 5.3.2) C Query Code\n",
    "The python function executing the query takes two parameters: `customer_id`, which represents the starting customer, and `k`, which indicates the degree of co-customers. The query utilizes the APOC `expandConfig` function to efficiently explore relationships up to a specified level. Starting from the customer node with the same ID as the passed `customer_id`, it navigates through `Make_transaction` relationships to `Terminal` or other `Customer` nodes. By using the `relationshipFilter` and `labelFilter` parameters, the query can precisely define the types of relationships and node labels to consider. The `maxLevel` parameter limits the exploration depth, ensuring that only paths with a length <= `k` are returned. The `uniqueness: 'NODE_GLOBAL'` setting guarantees that each node in the path appears only once.\n",
    "\n",
    "To focus only on paths of exact length `k`, after the `WITH` clause, a `WHERE` clause filters the results. Finally, the `RETURN` statement selects only the last node in each qualifying path, which represents the desired co-customer of interest.\n",
    "\n",
    "The `k` passed to the Python function is reworked in the query because the `maxLevel` parameter needs to specify the maximum number of nodes in the path. Since each co-customer requires a terminal between them and the immediately lower-degree co-customer, in the query, the python `k` becomes `(k - 1) * 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b6757b81-4740-4ae1-a397-4b803289a1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_c execution time: 0.69s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO_Customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CO_Customer]\n",
       "Index: []"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#customer_id is an integer that indicates the customer_id property of :Customer\n",
    "#k is an integer that indicates the different customers involved in the chain described in the project track\n",
    "def query_c(customer_id, k):\n",
    "    query = f\"\"\"\n",
    "            WITH {k-1} * 2 AS k\n",
    "            MATCH (start:Customer {{customer_id: {customer_id}}})\n",
    "            CALL apoc.path.expandConfig(start, {{\n",
    "                relationshipFilter: 'Make_transaction',\n",
    "                labelFilter: 'Terminal|Customer',\n",
    "                maxLevel: k,\n",
    "                uniqueness: 'NODE_GLOBAL'\n",
    "            }}) YIELD path\n",
    "\n",
    "            WITH path\n",
    "            WHERE length(path) = k\n",
    "            RETURN nodes(path)[-1].customer_id AS CO_Customer\n",
    "            \"\"\"\n",
    "    return execute_query_df(\"query_c\",query)\n",
    "query_c(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c835d-084b-4aa0-81dc-42df02430941",
   "metadata": {},
   "source": [
    "#### 5.3.3) C Performances\n",
    "The performance of this solution has pleasantly surprised me, especially considering that the query's requirements represent a potentially exponential task. Before arriving at this query, I tried various approaches with very poor results. Even calculating the \\(CC_3(1)\\) (the co-customer of degree \\(k = 3\\) starting from the customer with `customer_id = 1`) took an enormous amount of time, and attempting a `k > 3` resulted in no response, likely due to the excessive computational time required. \n",
    "\n",
    "With the proposed solution, however, it is possible to go far beyond `k = 3` while still maintaining remarkably low execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fc82b711-d6f6-4456-b33a-6e159ad4dc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_c execution time: 0.94s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO_Customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CO_Customer\n",
       "0            37\n",
       "1            94\n",
       "2            96\n",
       "3           142\n",
       "4           160\n",
       "5           191\n",
       "6             5\n",
       "7            41\n",
       "8            69\n",
       "9            75\n",
       "10          105\n",
       "11          112\n",
       "12          156\n",
       "13          192\n",
       "14            2\n",
       "15           91\n",
       "16           95\n",
       "17          101\n",
       "18          123\n",
       "19          190\n",
       "20           51\n",
       "21          104\n",
       "22           76\n",
       "23          164\n",
       "24          183\n",
       "25          199\n",
       "26           99\n",
       "27          130\n",
       "28          137\n",
       "29          170\n",
       "30           24\n",
       "31           58\n",
       "32          102\n",
       "33          168\n",
       "34          186\n",
       "35          189\n",
       "36          198\n",
       "37          114\n",
       "38          140\n",
       "39           73\n",
       "40           13\n",
       "41           17\n",
       "42           60\n",
       "43           86\n",
       "44          136\n",
       "45          153\n",
       "46          162\n",
       "47          172"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_c(1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc6e58-dd8b-454a-8818-0e6f05d6c930",
   "metadata": {},
   "source": [
    "To visualize the chain of customers and terminals, I executed the query in the Neo4j console, which returned the entire path. At one end of the path is the customer with `customer_id = 1`, while at the other end is the customer with `customer_id` equals to the one obtained in the previous query result.\n",
    "\n",
    "The data displayed inside the nodes in the image is not particularly meaningful, as it shows one of the properties of the nodes, which, in this case, is not relevant to the visualization.\n",
    "\n",
    "<img src=\"./assets/Query C path.png\" style=\"width:1100px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ac8d95-d56f-440a-9ce7-331dd47b295a",
   "metadata": {},
   "source": [
    "### 5.4) Query D\n",
    "#### 5.4.1) Query request\n",
    "> Extend the logical model that you have stored in the NOSQL database by introducing the following information (pay attention that this operation should be done once the NOSQL database has been already loaded with the data extracted from the datasets):\n",
    "\n",
    "> > i. Each transaction should be extended with:\n",
    "\n",
    "> > > 1. The period of the day {morning, afternoon, evening, night} in which the transaction has been executed.\n",
    "    \n",
    "> > > 2. The kind of products that have been bought through the transaction {hightech, food, clothing, consumable, other}\n",
    "\n",
    "> > > 3. The feeling of security expressed by the user. This is an integer value between 1 and 5 expressed by the user when conclude the transaction.\n",
    "\n",
    "> > The values can be chosen randomly.\n",
    "\n",
    "> > ii. Customers that make more than three transactions from the same terminal expressing a similar average feeling of security should be connected as\n",
    "“buying_friends”. Therefore also this kind of relationship should be explicitly stored in the NOSQL database and can be queried. Note, two average feelings of security are considered similar when their difference is lower than 1.\n",
    "\n",
    "The query is expressed clearly and leaves no room for alternative interpretations, so there is no need to explain further. For simplicity, we will split this query into two separate queries: `query_di` that performs point i, and `query_dii` that performs point ii, respectively.\n",
    "\n",
    "For both queries, the approach used is similar to the one employed during data loading. However, here we utilize the APOC `iterate` function, which allows us to define batch tasks and execute them in parallel. This approach enhances efficiency by parallelizing the execution of tasks. The `iterate` function takes three parameters: the query to be executed, the batch size, and whether to perform the operation in parallel.\n",
    "\n",
    "#### 5.4.2) Di Query Code\n",
    "The `query_di` itself has been divided into two functions: one for randomly modifying the existing database data by adding the data requested by the query, and another to pre-add new constraints to the existing schema. Unlike the data loading process, the schema creation occurs after the data modifications. This is because the data is already present, and creating the schema for the extended data before adding these new data would not work as intended. We need the additional data for the schema to be created correctly, as the existing data wouldn’t satisfy the new constraints otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1485b155-05ec-429e-b5af-126fd465ad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_di execution time: 0.60s\n",
      "create_transaction_extended_schema execution time: 1.80s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_di():\n",
    "    query = f\"\"\"\n",
    "        CALL apoc.periodic.iterate(\n",
    "            'MATCH (c:Customer)-[transaction:Make_transaction]->(t:Terminal) \n",
    "            RETURN transaction',\n",
    "            'SET transaction.tx_day_period = CASE toInteger(rand() * 4)\n",
    "                                                WHEN 0 THEN \"morning\" \n",
    "                                                WHEN 1 THEN \"afternoon\" \n",
    "                                                WHEN 2 THEN \"evening\" \n",
    "                                                ELSE \"night\" \n",
    "                                            END,\n",
    "                transaction.tx_products_type = CASE toInteger(rand() * 5) \n",
    "                                                    WHEN 0 THEN \"high-tech\" \n",
    "                                                    WHEN 1 THEN \"food\" \n",
    "                                                    WHEN 2 THEN \"clothing\" \n",
    "                                                    WHEN 3 THEN \"consumable\" \n",
    "                                                    ELSE \"other\" \n",
    "                                                END,\n",
    "                transaction.tx_security_feeling = toInteger(rand() * 5) + 1',\n",
    "            {{batchSize: {config[\"lines_per_commit\"]}, parallel: {config[\"parallel_loading\"]}}}\n",
    "        )\n",
    "    \"\"\"\n",
    "    return execute_query_commands(\"query_di\", [query])\n",
    "\n",
    "def create_transaction_extended_schema():\n",
    "    queries = [\n",
    "        \"CREATE CONSTRAINT tx_day_period_is_string FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_day_period IS :: STRING;\",\n",
    "        \"CREATE CONSTRAINT tx_day_period_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_day_period IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_products_type_is_string FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_products_type IS :: STRING;\",\n",
    "        \"CREATE CONSTRAINT tx_products_type_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_products_type IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_security_feeling_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_security_feeling IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_security_feeling_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_security_feeling IS NOT NULL;\",\n",
    "    ]\n",
    "    return execute_query_commands(\"create_transaction_extended_schema\", queries)\n",
    "    \n",
    "query_di()\n",
    "create_transaction_extended_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971be973-59ed-44ee-aca1-50c43991bb85",
   "metadata": {},
   "source": [
    "#### 5.4.3) Dii Query code\n",
    "aaa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5ab61-875c-4e5c-910d-eeee7256ced0",
   "metadata": {},
   "source": [
    "#### 5.4.3) Di and Dii Performances\n",
    "For the performance, there isn’t much to comment on, except that the modifications are done quickly and efficiently thanks to the APOC function. If the same operations were performed without using the APOC function, the times would undoubtedly be higher."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
