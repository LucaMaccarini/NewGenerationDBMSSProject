{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1fcd6c3",
   "metadata": {},
   "source": [
    "# New generation datamodels and DBMSS Project\n",
    "2023 / april 2025 edition\n",
    "\n",
    "Before diving into reading this notebook, make sure you have read the project guidelines provided by the professor. You can find them [here](./Project2023-vers1.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e01d1-ffc7-4f78-bf43-acbbe19cb409",
   "metadata": {},
   "source": [
    "## 1) Transaction Data Simulator Tool\n",
    "\n",
    "The section focuses on how the various provided scripts were combined to produce a single versatile script that, through the use of parameters, is capable of generating CSV files containing all the data that will be inserted into the database. We will omit explaining the functionality of the Python scripts or the meaning of the data generated by the tool, as these aspects are clearly detailed on the [linked page](https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_3_GettingStarted/SimulatedDataset.html).\n",
    "\n",
    "To proceed, the following Python packages and Python sources (from this project's repository) are required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d5306d3-a84f-42dd-ab03-e115c192b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from neo4j import PreviewWarning\n",
    "warnings.filterwarnings(\"ignore\", category=PreviewWarning)\n",
    "sys.path.append(os.path.join(os.getcwd(), '../GenerationScript/Transaction_data_simulator_code'))\n",
    "from add_frauds import add_frauds\n",
    "from generate_dataset import generate_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab3f3b",
   "metadata": {},
   "source": [
    "### 1.1) Parameters\n",
    "\n",
    "To manage parameters for the script in a simple way, I decided to use an array of objects. Each object represents the entire configuration for generating a single database, allowing the script to generate multiple databases with different characteristics and data volumes in one execution.\n",
    "\n",
    "Each object in the array, so each database configuration contains:\n",
    "\n",
    "- DB_name: The name of the database.\n",
    "- n_customers: The number of customers to generate.\n",
    "- n_terminals: The number of terminals to generate.\n",
    "- start_date: The starting date for generating transaction dates.\n",
    "- n_days: The number of days after the start_date to use for creating transaction dates.\n",
    "- radius: The action radius for customers. A customer can only perform transactions at a terminal within their radius.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d623f6c9",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "DBs = [\n",
    "   {\n",
    "       \"DB_name\": \"Small-DB-1\",\n",
    "       \"n_customers\": 500,\n",
    "       \"n_terminals\": 300,\n",
    "       \"n_days\": 7,\n",
    "       \"start_date\": '2024-12-30',\n",
    "       \"radius\": 10\n",
    "    },\n",
    "    {\n",
    "        \"DB_name\": \"Small-DB-2\",\n",
    "        \"n_customers\": 1000,\n",
    "        \"n_terminals\": 500,\n",
    "        \"n_days\": 14,\n",
    "        \"start_date\": '2024-01-01',\n",
    "        \"radius\": 5\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e01739-8ad8-4b0d-b4c4-479deec0a9e2",
   "metadata": {},
   "source": [
    "### 1.2) Generation Script\n",
    "\n",
    "Below is the commented code for generating the databases using the parameters defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4744055c-ee97-4bd0-a459-6dd87dbbe7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to generate customer profiles table: 0.01s\n",
      "Time to generate terminal profiles table: 0.00s\n",
      "Time to associate terminals to customers: 0.05s\n",
      "Time to generate transactions: 0.42s\n",
      "Number of frauds from scenario 1: 1\n",
      "Number of frauds from scenario 2: 127\n",
      "Number of frauds from scenario 3: 46\n",
      "Database data saved in: /mnt/1364D0FF74AFABFF/unimi/new generation/progetto/NewGenerationDBMSSProject/Generated_DBs/Small-DB-1/\n",
      "\n",
      "Time to generate customer profiles table: 0.01s\n",
      "Time to generate terminal profiles table: 0.00s\n",
      "Time to associate terminals to customers: 0.09s\n",
      "Time to generate transactions: 1.00s\n",
      "Number of frauds from scenario 1: 16\n",
      "Number of frauds from scenario 2: 852\n",
      "Number of frauds from scenario 3: 210\n",
      "Database data saved in: /mnt/1364D0FF74AFABFF/unimi/new generation/progetto/NewGenerationDBMSSProject/Generated_DBs/Small-DB-2/\n",
      "\n",
      "DONE! All DBs have been created\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"\"\n",
    "# Loop sui DB definiti nel file di configurazione\n",
    "for db in DBs:\n",
    "    # Generazione delle tabelle del DB usando i valori di configurazione\n",
    "    (customer_profiles_table, terminal_profiles_table, transactions_df) = generate_dataset(\n",
    "        n_customers=db[\"n_customers\"], \n",
    "        n_terminals=db[\"n_terminals\"], \n",
    "        nb_days=db[\"n_days\"], \n",
    "        start_date=db[\"start_date\"], \n",
    "        r=db[\"radius\"]\n",
    "    )\n",
    "\n",
    "    # Aggiungere frodi alle transazioni\n",
    "    transactions_df = add_frauds(customer_profiles_table, terminal_profiles_table, transactions_df)\n",
    "\n",
    "    \n",
    "    # Converto i valori della serie available_terminals dato che gli interi nella lista sono interi numpy\n",
    "    customer_profiles_table['available_terminals'] = customer_profiles_table['available_terminals'].apply(\n",
    "        lambda lst: [int(i) if isinstance(i, np.integer) else i for i in lst] if isinstance(lst, (list, np.array)) else lst\n",
    "    )\n",
    "\n",
    "    # Preparazione al salvataggio del DB\n",
    "    output_dir = os.path.join(os.getcwd(), '..', 'Generated_DBs', db[\"DB_name\"])\n",
    "\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Salvataggio dei customers\n",
    "    customer_profiles_table.to_csv(output_dir + '/customers.csv', sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "    # Salvataggio dei terminals\n",
    "    terminal_profiles_table.to_csv(output_dir + '/terminals.csv', sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "    # Salvataggio delle transactions\n",
    "    transactions_df.to_csv(output_dir + '/transactions.csv', sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "    print(f\"Database data saved in: {os.path.abspath(output_dir)}/\\n\")\n",
    "\n",
    "\n",
    "print(\"DONE! All DBs have been created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc7664f-110a-483a-b745-cf45712a853d",
   "metadata": {},
   "source": [
    "### 1.3) CSV Generati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c12f5-dbee-4269-80dc-d90249edfbae",
   "metadata": {},
   "source": [
    "Now, let's take a look at the generated CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48565d8-453d-4bc9-a6a1-219b0c0fc01c",
   "metadata": {},
   "source": [
    "#### Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcb212b5-92c1-46e0-ada7-dcdf9339fade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_customer_id</th>\n",
       "      <th>y_customer_id</th>\n",
       "      <th>mean_amount</th>\n",
       "      <th>std_amount</th>\n",
       "      <th>mean_nb_tx_per_day</th>\n",
       "      <th>available_terminals</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.881350</td>\n",
       "      <td>71.518937</td>\n",
       "      <td>62.262521</td>\n",
       "      <td>31.131260</td>\n",
       "      <td>2.179533</td>\n",
       "      <td>[29, 87, 144, 241, 330]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.365480</td>\n",
       "      <td>64.589411</td>\n",
       "      <td>46.570785</td>\n",
       "      <td>23.285393</td>\n",
       "      <td>3.567092</td>\n",
       "      <td>[5, 160, 242, 378, 431, 475]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.366276</td>\n",
       "      <td>38.344152</td>\n",
       "      <td>80.213879</td>\n",
       "      <td>40.106939</td>\n",
       "      <td>2.115580</td>\n",
       "      <td>[316, 406, 447]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.804456</td>\n",
       "      <td>92.559664</td>\n",
       "      <td>11.748426</td>\n",
       "      <td>5.874213</td>\n",
       "      <td>0.348517</td>\n",
       "      <td>[65, 94, 113, 364, 401, 433, 485]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.021840</td>\n",
       "      <td>83.261985</td>\n",
       "      <td>78.924891</td>\n",
       "      <td>39.462446</td>\n",
       "      <td>3.480049</td>\n",
       "      <td>[372]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>43.216661</td>\n",
       "      <td>36.225882</td>\n",
       "      <td>58.023111</td>\n",
       "      <td>29.011555</td>\n",
       "      <td>0.305376</td>\n",
       "      <td>[264, 309, 395, 412, 483]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4.034602</td>\n",
       "      <td>51.110309</td>\n",
       "      <td>7.707631</td>\n",
       "      <td>3.853816</td>\n",
       "      <td>0.238208</td>\n",
       "      <td>[32, 83, 194, 239, 280]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>37.634146</td>\n",
       "      <td>6.177907</td>\n",
       "      <td>41.619615</td>\n",
       "      <td>20.809807</td>\n",
       "      <td>0.967002</td>\n",
       "      <td>[147, 148, 185, 413]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>18.777030</td>\n",
       "      <td>40.467983</td>\n",
       "      <td>16.390871</td>\n",
       "      <td>8.195436</td>\n",
       "      <td>1.398557</td>\n",
       "      <td>[138]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>43.487363</td>\n",
       "      <td>83.000295</td>\n",
       "      <td>93.616587</td>\n",
       "      <td>46.808294</td>\n",
       "      <td>1.233354</td>\n",
       "      <td>[119, 471, 486]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x_customer_id  y_customer_id  mean_amount  std_amount  \\\n",
       "CUSTOMER_ID                                                          \n",
       "0                54.881350      71.518937    62.262521   31.131260   \n",
       "1                42.365480      64.589411    46.570785   23.285393   \n",
       "2                96.366276      38.344152    80.213879   40.106939   \n",
       "3                56.804456      92.559664    11.748426    5.874213   \n",
       "4                 2.021840      83.261985    78.924891   39.462446   \n",
       "...                    ...            ...          ...         ...   \n",
       "995              43.216661      36.225882    58.023111   29.011555   \n",
       "996               4.034602      51.110309     7.707631    3.853816   \n",
       "997              37.634146       6.177907    41.619615   20.809807   \n",
       "998              18.777030      40.467983    16.390871    8.195436   \n",
       "999              43.487363      83.000295    93.616587   46.808294   \n",
       "\n",
       "             mean_nb_tx_per_day                available_terminals  \n",
       "CUSTOMER_ID                                                         \n",
       "0                      2.179533            [29, 87, 144, 241, 330]  \n",
       "1                      3.567092       [5, 160, 242, 378, 431, 475]  \n",
       "2                      2.115580                    [316, 406, 447]  \n",
       "3                      0.348517  [65, 94, 113, 364, 401, 433, 485]  \n",
       "4                      3.480049                              [372]  \n",
       "...                         ...                                ...  \n",
       "995                    0.305376          [264, 309, 395, 412, 483]  \n",
       "996                    0.238208            [32, 83, 194, 239, 280]  \n",
       "997                    0.967002               [147, 148, 185, 413]  \n",
       "998                    1.398557                              [138]  \n",
       "999                    1.233354                    [119, 471, 486]  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(os.path.join(output_dir, 'customers.csv'), sep=';', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a29e7a5-d9b6-4e4b-8ef4-54d84a9ed8ee",
   "metadata": {},
   "source": [
    "#### Terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dfd3649-9afb-4440-9863-4fb1eadeba66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_terminal_id</th>\n",
       "      <th>y_terminal_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.702200</td>\n",
       "      <td>72.032449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011437</td>\n",
       "      <td>30.233257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.675589</td>\n",
       "      <td>9.233859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.626021</td>\n",
       "      <td>34.556073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.676747</td>\n",
       "      <td>53.881673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>81.250730</td>\n",
       "      <td>28.380183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>52.784680</td>\n",
       "      <td>33.941672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>55.466731</td>\n",
       "      <td>97.440347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>31.170292</td>\n",
       "      <td>66.879661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>32.596721</td>\n",
       "      <td>77.447727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x_terminal_id  y_terminal_id\n",
       "TERMINAL_ID                              \n",
       "0                41.702200      72.032449\n",
       "1                 0.011437      30.233257\n",
       "2                14.675589       9.233859\n",
       "3                18.626021      34.556073\n",
       "4                39.676747      53.881673\n",
       "...                    ...            ...\n",
       "495              81.250730      28.380183\n",
       "496              52.784680      33.941672\n",
       "497              55.466731      97.440347\n",
       "498              31.170292      66.879661\n",
       "499              32.596721      77.447727\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(output_dir, 'terminals.csv'), sep=';', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338c7ff-e76e-4a56-a4fd-daae427cb364",
   "metadata": {},
   "source": [
    "#### Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2384961-3d3b-40d4-b7c3-7e0a713ab315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TX_DATETIME</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th>TX_AMOUNT</th>\n",
       "      <th>TX_TIME_SECONDS</th>\n",
       "      <th>TX_TIME_DAYS</th>\n",
       "      <th>TX_FRAUD</th>\n",
       "      <th>TX_FRAUD_SCENARIO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:31</td>\n",
       "      <td>596</td>\n",
       "      <td>110</td>\n",
       "      <td>57.16</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 00:07:56</td>\n",
       "      <td>2</td>\n",
       "      <td>316</td>\n",
       "      <td>146.00</td>\n",
       "      <td>476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 00:10:34</td>\n",
       "      <td>927</td>\n",
       "      <td>415</td>\n",
       "      <td>50.99</td>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 00:10:45</td>\n",
       "      <td>568</td>\n",
       "      <td>400</td>\n",
       "      <td>44.71</td>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 00:13:44</td>\n",
       "      <td>541</td>\n",
       "      <td>171</td>\n",
       "      <td>59.07</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25206</th>\n",
       "      <td>2024-01-14 23:45:57</td>\n",
       "      <td>786</td>\n",
       "      <td>104</td>\n",
       "      <td>40.75</td>\n",
       "      <td>1208757</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25207</th>\n",
       "      <td>2024-01-14 23:46:06</td>\n",
       "      <td>392</td>\n",
       "      <td>134</td>\n",
       "      <td>7.15</td>\n",
       "      <td>1208766</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25208</th>\n",
       "      <td>2024-01-14 23:46:40</td>\n",
       "      <td>888</td>\n",
       "      <td>141</td>\n",
       "      <td>37.55</td>\n",
       "      <td>1208800</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25209</th>\n",
       "      <td>2024-01-14 23:51:33</td>\n",
       "      <td>347</td>\n",
       "      <td>64</td>\n",
       "      <td>23.28</td>\n",
       "      <td>1209093</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25210</th>\n",
       "      <td>2024-01-14 23:56:53</td>\n",
       "      <td>164</td>\n",
       "      <td>212</td>\n",
       "      <td>66.56</td>\n",
       "      <td>1209413</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25211 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        TX_DATETIME  CUSTOMER_ID  TERMINAL_ID  TX_AMOUNT  \\\n",
       "TRANSACTION_ID                                                             \n",
       "0               2024-01-01 00:00:31          596          110      57.16   \n",
       "1               2024-01-01 00:07:56            2          316     146.00   \n",
       "2               2024-01-01 00:10:34          927          415      50.99   \n",
       "3               2024-01-01 00:10:45          568          400      44.71   \n",
       "4               2024-01-01 00:13:44          541          171      59.07   \n",
       "...                             ...          ...          ...        ...   \n",
       "25206           2024-01-14 23:45:57          786          104      40.75   \n",
       "25207           2024-01-14 23:46:06          392          134       7.15   \n",
       "25208           2024-01-14 23:46:40          888          141      37.55   \n",
       "25209           2024-01-14 23:51:33          347           64      23.28   \n",
       "25210           2024-01-14 23:56:53          164          212      66.56   \n",
       "\n",
       "                TX_TIME_SECONDS  TX_TIME_DAYS  TX_FRAUD  TX_FRAUD_SCENARIO  \n",
       "TRANSACTION_ID                                                              \n",
       "0                            31             0         0                  0  \n",
       "1                           476             0         0                  0  \n",
       "2                           634             0         0                  0  \n",
       "3                           645             0         0                  0  \n",
       "4                           824             0         0                  0  \n",
       "...                         ...           ...       ...                ...  \n",
       "25206                   1208757            13         0                  0  \n",
       "25207                   1208766            13         0                  0  \n",
       "25208                   1208800            13         0                  0  \n",
       "25209                   1209093            13         0                  0  \n",
       "25210                   1209413            13         0                  0  \n",
       "\n",
       "[25211 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(output_dir, 'transactions.csv'), sep=';', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb8392b-ce13-4d86-b5c7-d6d12aabc795",
   "metadata": {},
   "source": [
    "### 1.4) CSV Generati\n",
    "In the project guidelines, it is requested to generate three databases: one with a size of 50 MB, one with 100 MB, and one with 200 MB. The database generation script does not allow you to directly define the size of the database you want to generate. Instead, you must specify all the previously viewed parameters. After conducting some tests, I defined the parameters reported in the example to generate the three databases with the desired sizes.\n",
    "\n",
    "Note that the generated databases represent scenarios with a high volume of transactions and a limited number of customers and terminals. This characteristic should be considered when evaluating performance, as it represents the worst-case scenario that could occur in our workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e98635-503b-4cd9-860f-451457963a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69cd624c-46c3-4f07-a8b8-f3e58796b4f2",
   "metadata": {},
   "source": [
    "## 2) Conceptual Model\n",
    "\n",
    "To create the following conceptual model, I analyzed the CSV files generated by the *Transaction Data Simulator* tool. This analysis allowed me to understand the data's semantics and design a clear and simple structure that illustrates the relationships between the data to be stored in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7225c-f30e-4129-aa42-5f9837bd76d4",
   "metadata": {},
   "source": [
    "<img src=\"./assets/Conceptual model UML.svg\" alt=\"UML Diagram\" style=\"width:800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9b0af-a1db-4aad-b8ce-ab071041fd14",
   "metadata": {},
   "source": [
    "### 2.2) Costraints\n",
    "#### Terminal\n",
    "- 0 <= `coords.x` <= 100\n",
    "- 0 <= `coords.y` <= 100\n",
    "\n",
    "#### Customer\n",
    "- 0 <= `coords.x` <= 100\n",
    "- 0 <= `coords.y` <= 100\n",
    "- `spending_mean` >= 0\n",
    "- `spending_std` >= 0\n",
    "- `transactions_per_day_mean` >= 0\n",
    "\n",
    "#### Transactions\n",
    "- `amount` > 0\n",
    "- 0 <= `fraud_scenario` <= 3\n",
    "- 0 <= `security_feeling` <= 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1cadaf-07f9-4964-8509-e3bed43d7c1c",
   "metadata": {},
   "source": [
    "## 3) Logical Model\n",
    "\n",
    "Before proceeding with the logical model, it is important to indicate which database I have chosen to manage the data and the decisions I made regarding the representation of the data to meet the workload requirements.\n",
    "\n",
    "### 3.1) Database\n",
    "As a database, I chose to use Neo4j due to the nature of the data, which suggests a graph structure. Infact, all the relationships present are of the N:N type, and such relationships are excellently handled by graph databases. \n",
    "\n",
    "Furthermore, this choice was confirmed by the workload, especially by query 3c, which involves continuous traversal of relationships up to a certain `K` value that determines when to stop. Performing this query would be extremely costly if we had to perform a join (or lookup) for each traversed relationship. \n",
    "\n",
    "Additionally, as we will see later, Cypher, Neo4j's query language, offers a library called APOC that will allow us to execute query 3c with impressive performance.\n",
    "\n",
    "### 3.2) Data representation (Workload friendly)\n",
    "Since Neo4j does not allow the definition of custom types or the insertion of objects within node properties, I decided to eliminate all custom types and implement them using primitive types. For the custom types representing objects, I created a property for each attribute with its corresponding primitive type. For enums, I used simple strings.\n",
    "\n",
    "The attribute names in the logical model differ from those in the conceptual model because they are based on those used by the *Transaction Data Simulator* tool. The meaning of any unclear or newly introduced fields can be determined by:  \n",
    "- Referring to the *Transaction Data Simulator* tool documentation for fields generated by the tool.  \n",
    "- Reading the following paragraph, where I explain the new fields I added.  \n",
    "- Consulting the project guidelines, which detail and justify the fields explicitly required in the extended database.  \n",
    "\n",
    "As we will see later, to improve the efficiency of the workload through indexing, I decided to split the `transactions.registration` field into its components: day, month, year, and time. These components are now represented as `tx_date_day`, `tx_date_month`, `tx_date_year`, and `tx_date_time`, respectively. This division was made because many queries in the workload filter data using only the month and year of the `transactions.registration` field. If I had created an index on the entire field, it would not have been used, as the filters in the queries would only utilize a subset of the entire field. Therefore, the division was made, and a composite index was created only on the year and month fields.\n",
    "\n",
    "The data types specified are those present in Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff40efb-95e5-4285-a131-1b0e61bf7a93",
   "metadata": {},
   "source": [
    "<img src=\"./assets/Logical model UML.svg\" alt=\"UML Diagram\" style=\"width:800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35c04e6-2e07-463d-af89-5863a1ed487a",
   "metadata": {},
   "source": [
    "### 3.3) Costraints\n",
    "#### Terminal\n",
    "- 0 <= `x_terminal_id` <= 100\n",
    "- 0 <= `y_terminal_id` <= 100\n",
    "\n",
    "#### Customer\n",
    "- 0 <= `x_customer_id` <= 100\n",
    "- 0 <= `y_customer_id` <= 100\n",
    "- `mean_amount` >= 0\n",
    "- `std_amount` >= 0\n",
    "- `mean_nb_tx_per_day` >= 0\n",
    "\n",
    "#### Transactions\n",
    "- `tx_amount` > 0\n",
    "- 0 <= `tx_fraud_scenario` <= 3\n",
    "- 0 <= `tx_security_feeling` <= 5\n",
    "- `tx_date_day`, `tx_date_month`, `tx_date_year` form a correct date type object \n",
    "- `tx_date_time` forms a correct localTime object\n",
    "- `tx_day_period` is one of the following strings [\"morning\", \"afternoon\", \"evening\", \"night\"]\n",
    "- `tx_products_type` is one of the following strings [\"high-tech\", \"food\", \"clothing\", \"consumable\", \"other\"]\n",
    "\n",
    "### 3.4) Assumptions\n",
    "Since the constraints that can be implemented in Neo4j focus only on the structure and data type, and do not allow constraints on the actual values or the direction of relationships, I assume that whichever software provides the data to be inserted into the database has correctly implemented all the constraints listed above (except for the constraints on the properties `tx_date_...`, since those can be validated at the database level). In our case, we assume that the values produced by the *Transaction Data Simulator* tool are correct and comply with the constraints. \n",
    "\n",
    "Since Neo4j constraints also do not allow us to define the direction of relationships, it is our responsibility to ensure that, in the queries used to create relationships, we do not make mistakes and avoid generating relationships in the wrong direction.\n",
    "\n",
    "For more detailed information, I refer you to the Neo4j [documentation](https://neo4j.com/docs/cypher-manual/current/constraints/managing-constraints/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39af186-d0a2-4bf5-b597-b8f5a350bc51",
   "metadata": {},
   "source": [
    "## 4) Neo4j Data Loading\n",
    "To proceed with this section, the following Python packages are required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95383e31-f7c8-4b24-a4e9-0facf81aecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7822175-8e8e-4ac4-93da-66f667091953",
   "metadata": {},
   "source": [
    "To facilitate interactions with Neo4j, we will define some \"kernel\" functions that will be used to interface with the database. These functions will simplify managing data with Neo4j, providing reusable methods for the rest of the project.\n",
    "\n",
    "Before defining the kernel functions, we set some configuration parameters that will be useful not only for the kernel functions themselves but also for the various queries that will be executed later in the project through the kernel functions.\n",
    "Among the configuration parameters, we have:\n",
    "- `customers_csv_link`, `terminals_csv_link`, `transactions_csv_link`: these are references to the previously generated CSV files. They can be local paths or network links, and we will explain in the appropriate section why we use network links. The files used in to the example **the total size of the three files is 50 MB**. However, in the performance analysis section, we will also include load times for both larger and smaller databases.\n",
    "- `lines_per_commit`: useful for batch operations sent to the database through specific Cypher directives (in our case, we will use APOC). This parameter indicates how many modified or added rows should be processed before committing the data.\n",
    "- `parallel_loading`: useful for the batch operations mentioned in the previous point. This parameter indicates whether the database should perform the batch operations in parallel or sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c58278ee-178d-4b60-b1ff-88abd5045d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config parameters\n",
    "config = {\n",
    "    \"customers_csv_link\": \"https://www.dropbox.com/scl/fi/8ctho6t1xd2hn00ht36l3/customers.csv?rlkey=rgxpnpwrfesfui6mtdz1nnedd&st=dlfsg22x&dl=1\",\n",
    "    \"terminals_csv_link\": \"https://www.dropbox.com/scl/fi/3p86oc2gnoo24q4qg7czc/terminals.csv?rlkey=z13kfwu7f3uezp1pu26k7qmtk&st=pt24zewq&dl=1\",\n",
    "    \"transactions_csv_link\": \"https://www.dropbox.com/scl/fi/6tygyhhen8nxfqpzlg66s/transactions.csv?rlkey=q342g524lh558p9t2c39bx1gf&st=kwgctxrj&dl=1\",\n",
    "    \"lines_per_commit\": 1000,\n",
    "    \"parallel_loading\": \"true\"\n",
    "}\n",
    "\n",
    "# provide neo4j db connection\n",
    "def get_neo4j_connection():\n",
    "    try:\n",
    "        #Using environment variables (recommended): This method securely stores credentials outside the code by using environment variables.\n",
    "        #uri = os.getenv('NEO4J_URI')\n",
    "        #user = os.getenv('NEO4J_USERNAME')\n",
    "        #password = os.getenv('NEO4J_PASSWORD')\n",
    "        \n",
    "        #Using plain strings (not recommended): This method directly includes credentials in the code, which exposes them to potential security risks.\n",
    "        #In this case, to keep things as simple as possible, I will use plain text credentials since they are for a free version of Neo4j.\n",
    "        #You can create it by following this link: https://neo4j.com/product/auradb\n",
    "        uri = \"neo4j+s://45d4bc57.databases.neo4j.io\"\n",
    "        user = \"neo4j\"\n",
    "        password = \"o8mbh0hFGILahScLJw2yTYWIwQ6z7lPhQT6m-U2W1c8\"\n",
    "        \n",
    "        return neo4j.GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: An unexpected error occurred while connecting to Neo4j: {e}\")\n",
    "        return None\n",
    "\n",
    "# close neo4j db connection\n",
    "def close_neo4j_connection(driver):\n",
    "    if driver is not None:\n",
    "        driver.close()\n",
    "\n",
    "# clear the db from data, relations and costraints\n",
    "def clear_database():\n",
    "    driver = get_neo4j_connection()\n",
    "    if driver is None:\n",
    "        return False\n",
    "\n",
    "    delete_nodes_query = f\"\"\"\n",
    "        MATCH (n)\n",
    "        CALL apoc.nodes.delete(n, {config[\"lines_per_commit\"]}) YIELD value\n",
    "        RETURN value\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        start_time=time.time()\n",
    "        driver.execute_query(delete_nodes_query)\n",
    "\n",
    "        constraints_result = driver.execute_query(\"SHOW CONSTRAINTS\").records\n",
    "        for record in constraints_result:\n",
    "            drop_constraint_query = \"DROP CONSTRAINT $name\"\n",
    "            driver.execute_query(drop_constraint_query, {\"name\": record[\"name\"]})\n",
    "\n",
    "        indexes_result = driver.execute_query(\"SHOW INDEXES\").records\n",
    "        for record in indexes_result:\n",
    "            drop_index_query = \"DROP INDEX $name\"\n",
    "            driver.execute_query(drop_index_query, {\"name\": record[\"name\"]})\n",
    "\n",
    "        print(\"clear_database execution time: {:.2f}s\".format(time.time()-start_time))\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR clear_database: {e}\")\n",
    "        return False\n",
    "\n",
    "    finally:\n",
    "        close_neo4j_connection(driver)\n",
    "\n",
    "# Performs a query that does not expect data as a result\n",
    "def execute_query_command(name, query):\n",
    "    driver = get_neo4j_connection()\n",
    "    try:\n",
    "        start_time=time.time()\n",
    "        driver.execute_query(query)\n",
    "        print(f\"{name} execution time: {{:.2f}}s\".format(time.time()-start_time))\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR {name}: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        close_neo4j_connection(driver)\n",
    "        \n",
    "# Performs some querys where each one does not expect data as a result\n",
    "def execute_query_commands(name, queries):\n",
    "    driver = get_neo4j_connection()\n",
    "    try:\n",
    "        start_time=time.time()\n",
    "        \n",
    "        for query in queries:\n",
    "            driver.execute_query(query)\n",
    "\n",
    "        print(f\"{name} execution time: {{:.2f}}s\".format(time.time()-start_time))\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR {name}: {e}\")\n",
    "        return False\n",
    "    finally:\n",
    "        close_neo4j_connection(driver)\n",
    "\n",
    "# performs a query that returns data and converts it to a dataframe\n",
    "def execute_query_df(name, query):\n",
    "    driver = get_neo4j_connection()\n",
    "    if driver is None:\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        start_time=time.time()\n",
    "        result = driver.execute_query(query, result_transformer_= neo4j.Result.to_df)\n",
    "        print(f\"{name} execution time: {{:.2f}}s\".format(time.time() - start_time))\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR {name}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        close_neo4j_connection(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098dadb5-4648-420c-b573-ab23124907dc",
   "metadata": {},
   "source": [
    "**Let’s begin by cleaning the database.** This step is unnecessary if you have just created a new database instance, but if you are reusing an instance on which you have already performed some operations, such as running this notebook before, it is advisable to restore it to its original state by clearing everything. In this case, the `clear_database()` function comes to our aid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73ad3ab8-2b74-46dd-a5ae-f02d0092de6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear_database execution time: 4.42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893ebdd-a7d9-4b76-912e-0923b67c4c4f",
   "metadata": {},
   "source": [
    "### 4.1) Schema\n",
    "Neo4j constraints focus solely on the data structure, as they are used to define a schema for the data. Thanks to Neo4j's schemaless nature, or more generally the schemaless nature of NoSQL databases, it is possible to insert data with maximum flexibility, without the need to define a formal schema in advance. This flexibility allows for handling heterogeneous data and adapting to changes over time, making it ideal for scenarios where the data structure may evolve.\n",
    "\n",
    "However, despite this flexibility, defining a schema is still considered good practice. It provides several benefits, particularly in terms of performance when running queries that filter data or when calculations need to be performed on the data. By enforcing data types and data presence through the schema, the database can optimize certain operations, especially those that involve processing already present values. On the other hand, one drawback of using a schema is that it requires additional processing during insertions and modifications, as the database must validate that each new piece of data complies with the defined constraints.\n",
    "\n",
    "The schema we are about to define in the database involves taking the previously documented logical model and:\n",
    "- adding constraints that associate each attribute with its respective type;\n",
    "- defining, for each entity (from the logical model), the attributes that form the primary key.\n",
    "- Adding constraints that make the attributes mandatory, for attributes not specified as primary keys, since they are already mandatory due to the primary key constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33ffa2bc-6bfb-4fba-a28d-954560379160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_terminals_schema execution time: 1.08s\n",
      "create_customers_schema execution time: 1.78s\n",
      "create_transaction_schema execution time: 2.85s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_terminals_schema():\n",
    "    queries = [\n",
    "        \"CREATE CONSTRAINT terminal_id_is_integer FOR (t:Terminal) REQUIRE t.terminal_id IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT terminal_id_key FOR (t:Terminal) REQUIRE t.terminal_id IS NODE KEY;\",\n",
    "        \"CREATE CONSTRAINT terminal_x_is_float FOR (t:Terminal) REQUIRE t.x_terminal_id IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT terminal_x_required FOR (t:Terminal) REQUIRE t.x_terminal_id IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT terminal_y_is_float FOR (t:Terminal) REQUIRE t.y_terminal_id IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT terminal_y_required FOR (t:Terminal) REQUIRE t.y_terminal_id IS NOT NULL;\"\n",
    "    ]\n",
    "    \n",
    "    return execute_query_commands(\"create_terminals_schema\", queries)\n",
    "\n",
    "def create_customers_schema():\n",
    "    queries = [\n",
    "        \"CREATE CONSTRAINT customer_id_is_integer FOR (c:Customer) REQUIRE c.customer_id IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT customer_id_key FOR (c:Customer) REQUIRE c.customer_id IS NODE KEY;\",\n",
    "        \"CREATE CONSTRAINT customer_x_is_float FOR (c:Customer) REQUIRE c.x_customer_id IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT customer_x_required FOR (c:Customer) REQUIRE c.x_customer_id IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT customer_y_is_float FOR (c:Customer) REQUIRE c.y_customer_id IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT customer_y_required FOR (c:Customer) REQUIRE c.y_customer_id IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT customer_mean_amount_is_float FOR (c:Customer) REQUIRE c.mean_amount IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT customer_mean_amount_required FOR (c:Customer) REQUIRE c.mean_amount IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT customer_std_amount_is_float FOR (c:Customer) REQUIRE c.std_amount IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT customer_std_amount_required FOR (c:Customer) REQUIRE c.std_amount IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT customer_mean_nb_tx_per_day_is_float FOR (c:Customer) REQUIRE c.mean_nb_tx_per_day IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT customer_mean_nb_tx_per_day_required FOR (c:Customer) REQUIRE c.mean_nb_tx_per_day IS NOT NULL;\"\n",
    "    ]\n",
    "    return execute_query_commands(\"create_customers_schema\", queries)\n",
    "\n",
    "def create_transaction_schema():\n",
    "    queries = [\n",
    "        \"CREATE CONSTRAINT transaction_id_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.transaction_id IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT transaction_id_key FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.transaction_id IS RELATIONSHIP KEY;\",\n",
    "        \"CREATE CONSTRAINT tx_time_seconds_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_time_seconds IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_time_seconds_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_time_seconds IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_time_days_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_time_days IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_time_days_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_time_days IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_amount_is_float FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_amount IS :: FLOAT;\",\n",
    "        \"CREATE CONSTRAINT tx_amount_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_amount IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_date_day_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_day IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_date_day_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_day IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_date_month_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_month IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_date_month_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_month IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_date_year_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_year IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_date_year_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_year IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_date_time_is_localtime FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_time IS :: LOCAL TIME;\",\n",
    "        \"CREATE CONSTRAINT tx_date_time_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_date_time IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_fraud_is_boolean FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_fraud IS :: BOOLEAN;\",\n",
    "        \"CREATE CONSTRAINT tx_fraud_is_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_fraud IS NOT NULL;\",\n",
    "        \"CREATE CONSTRAINT tx_fraud_scenario_is_integer FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_fraud_scenario IS :: INTEGER;\",\n",
    "        \"CREATE CONSTRAINT tx_fraud_scenario_is_required FOR ()-[transaction:Make_transaction]->() REQUIRE transaction.tx_fraud_scenario IS NOT NULL;\"\n",
    "    ]\n",
    "    return execute_query_commands(\"create_transaction_schema\", queries)\n",
    "\n",
    "create_terminals_schema()\n",
    "create_customers_schema()\n",
    "create_transaction_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8776b-b0f4-490f-a03e-747dbd8cc818",
   "metadata": {},
   "source": [
    "### 4.2) Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a230cf7a-cfbc-4387-9f0d-e02f4f9cb736",
   "metadata": {},
   "source": [
    "To load data into Neo4j using CSV files, we must first consider where the Neo4j instance resides in which we want to load the data. This aspect is crucial because the CSV files must be accessible from the machine running the Neo4j instance. This results in two possible scenarios:\n",
    "- The CSV files reside on the machine where the Neo4j instance is running,\n",
    "- The CSV files are network resources that can be directly downloaded via a link.\n",
    "\n",
    "Since we are using a Neo4j instance managed by an external company, Aura, they obviously do not provide us access to their servers, so we must opt for the second option.\n",
    "\n",
    "This will have an impact on the data loading performance, as the time indicated by the loading procedure will not only account for the time required to load the data from the file to the database but will also include the time for the Neo4j instance to download the file. The download time is not negligible because, as we know, the network is much slower compared to a completely local approach. Check it yourself by pasting the transactions CSV file URL into your browser and seeing how long it takes for your machine to download the file.\n",
    "\n",
    "It’s important to use a direct download link for the CSV files to ensure everything works. For easily and quickly sharing these files, I chose Dropbox because it offers a file sharing option with links that include a query parameter in the URL. This parameter, appearing as `&dl=1` at the end of the link, allows me to specify whether the link should be a direct download. This feature is crucial for the Neo4j instance to download the file correctly. I also explored other cloud storage systems, but the process of obtaining a direct download link was unnecessarily more complex.\n",
    "\n",
    "Now let's look at the queries used to load the data into the database. Initially, I wanted to load the data using the same example provided by the professor during the lessons, where a Cypher directive was used to load data from a CSV file in batches of N rows per commit. However, since this directive has been deprecated, I opted to use the APOC library, which allowed me to achieve the same behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d33bb27-1736-4e1a-aa16-b2e7d459dd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_terminals_from_csv execution time: 2.08s\n",
      "load_customers_with_available_terminals_from_csv execution time: 3.46s\n",
      "load_transactions_from_csv execution time: 77.68s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_terminals_from_csv():\n",
    "    query = f\"\"\"\n",
    "        CALL apoc.periodic.iterate(\n",
    "            'LOAD CSV WITH HEADERS FROM \"{config[\"terminals_csv_link\"]}\" AS row FIELDTERMINATOR \";\" \n",
    "            RETURN row',\n",
    "            'MERGE (t:Terminal {{terminal_id: toInteger(row.TERMINAL_ID)}})\n",
    "            ON CREATE SET \n",
    "                t.x_terminal_id = toFloat(row.x_terminal_id),\n",
    "                t.y_terminal_id = toFloat(row.y_terminal_id)\n",
    "            ',\n",
    "            {{batchSize: {config[\"lines_per_commit\"]}, parallel: {config[\"parallel_loading\"]}}}\n",
    "        )\n",
    "    \"\"\"\n",
    "    return execute_query_command(\"load_terminals_from_csv\", query)\n",
    "\n",
    "def load_customers_with_available_terminals_from_csv():    \n",
    "    query = f\"\"\"\n",
    "        CALL apoc.periodic.iterate(\n",
    "            'LOAD CSV WITH HEADERS FROM \"{config[\"customers_csv_link\"]}\" AS row FIELDTERMINATOR \";\" \n",
    "            RETURN row',\n",
    "            'MERGE (c:Customer {{customer_id: toInteger(row.CUSTOMER_ID)}})\n",
    "            ON CREATE SET  \n",
    "                c.x_customer_id = toFloat(row.x_customer_id),\n",
    "                c.y_customer_id = toFloat(row.y_customer_id),\n",
    "                c.mean_amount = toFloat(row.mean_amount),\n",
    "                c.std_amount = toFloat(row.std_amount),\n",
    "                c.mean_nb_tx_per_day = toFloat(row.mean_nb_tx_per_day)\n",
    "            WITH c, row\n",
    "            WITH c, apoc.convert.fromJsonList(row.available_terminals) AS available_terminal_ids\n",
    "            UNWIND available_terminal_ids AS available_terminal_id\n",
    "            MATCH (t:Terminal {{terminal_id: available_terminal_id}})\n",
    "            MERGE (c)-[:Available]->(t)\n",
    "            ',\n",
    "            {{batchSize: {config[\"lines_per_commit\"]}, parallel: {config[\"parallel_loading\"]}}}\n",
    "        )\n",
    "    \"\"\"\n",
    "    return execute_query_command(\"load_customers_with_available_terminals_from_csv\",query)\n",
    "\n",
    "def load_transactions_from_csv():\n",
    "    query = f\"\"\"\n",
    "        CALL apoc.periodic.iterate(\n",
    "            'LOAD CSV WITH HEADERS FROM \"{config[\"transactions_csv_link\"]}\" AS row FIELDTERMINATOR \";\" \n",
    "            RETURN row',\n",
    "            'WITH row,\n",
    "                  split(row.TX_DATETIME, \" \") AS splitted_date_time\n",
    "                  \n",
    "            WITH row,\n",
    "                 date(splitted_date_time[0]) AS parsed_date,\n",
    "                 localtime(splitted_date_time[1]) AS parsed_local_time\n",
    "\n",
    "            MATCH (c:Customer {{customer_id: toInteger(row.CUSTOMER_ID)}}), \n",
    "                (t:Terminal {{terminal_id: toInteger(row.TERMINAL_ID)}})\n",
    "            MERGE (c)-[transaction:Make_transaction {{transaction_id: toInteger(row.TRANSACTION_ID)}}]->(t)\n",
    "            ON CREATE SET \n",
    "                transaction.tx_time_seconds = toInteger(row.TX_TIME_SECONDS), \n",
    "                transaction.tx_time_days = toInteger(row.TX_TIME_DAYS),\n",
    "                transaction.tx_amount = toFloat(row.TX_AMOUNT), \n",
    "                transaction.tx_fraud = toBoolean(toInteger(row.TX_FRAUD)), \n",
    "                transaction.tx_fraud_scenario = toInteger(row.TX_FRAUD_SCENARIO),\n",
    "\n",
    "                transaction.tx_date_day = parsed_date.day,\n",
    "                transaction.tx_date_month = parsed_date.month,\n",
    "                transaction.tx_date_year = parsed_date.year, \n",
    "                transaction.tx_date_time = parsed_local_time \n",
    "            ',\n",
    "            {{batchSize: {config[\"lines_per_commit\"]}, parallel: {config[\"parallel_loading\"]}}}\n",
    "        )\n",
    "    \"\"\"\n",
    "    return execute_query_command(\"load_transactions_from_csv\",query)\n",
    "\n",
    "load_terminals_from_csv()\n",
    "load_customers_with_available_terminals_from_csv()\n",
    "load_transactions_from_csv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ffc76c-18c7-4ddd-a0b5-749390db5388",
   "metadata": {},
   "source": [
    "## 5) Workload\n",
    "In this section, I’ll explain how I implemented the queries to efficiently respond to the various requests outlined in the project specifications. Since the requested queries were not always precise in every detail, each query’s analysis will follow these key points:\n",
    "- Report the query as expressed in the project specifications.\n",
    "- Explain my interpretation of the query.\n",
    "- Explain how i have built the query, providing the query code\n",
    "- Look at the results\n",
    "- Evaluate the query's performance.\n",
    "\n",
    "Others queries performance details will be included in the dedicated section, where the execution times of the various queries will be compared across databases of different sizes.\n",
    "\n",
    "**An important note:** since I couldn’t find a way to clear the caches in the free Neo4j instance (and I don’t think it’s possible), when comparing the execution times of different versions of the same query, or the same query on different DBs, **it’s important to ensure the accuracy of the timings by running them multiple times**, so we will look at the chached queries timing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e41734-85e9-4fe2-be18-43cadd3afe18",
   "metadata": {},
   "source": [
    "### 5.1) Query A\n",
    "#### 5.1.1) Query request\n",
    "> For each customer checks that the spending frequency and the spending amounts of the last month is under the usual spending frequency and the spending amounts for the same period.\n",
    "\n",
    "- \"for each customer\": this indicates that the query results must include all customers, even those for whom it is not possible to calculate the requested data.  \n",
    "\n",
    "- \"of the last month\": refers to the month preceding the one provided as a parameter in the query. To call the python function that executes this query you have to specify partial date in the \"yyyy-MM\" format as a parameter. This date is then used to calculate the `first_of_previous_month` variable within the query. This variable represents the first day of the month immediately prior to the given date. When determining the value of `first_of_previous_month`, only the month and year are considered, ensuring that the query correctly filters data relevant to the previous month.  \n",
    "\n",
    "- \"usual spending frequency and the spending amounts for the same period\": I interpreted this to mean that the spending frequency and spending amount must be calculated as the average of all spending frequencies and amounts recorded in the database that match the same month but correspond to a year earlier than the `first_of_previous_month` variable.\n",
    "\n",
    "#### 5.1.2) A1 query code\n",
    "Let's provide a first version of the query A\n",
    "\n",
    "The query starts by calculating the date corresponding to the first day of the previous month relative to the date provided to the Python function. This date is saved in the variable `first_of_previous_month`.\n",
    "\n",
    "Next, all customers are matched to ensure that none are excluded from the final result of the query. This is done because the following `WHERE` clauses do not filter out customers, and all subsequent matches are `OPTIONAL MATCH`.\n",
    "\n",
    "The first `OPTIONAL MATCH` is used to retrieve the transaction history for the same period, this transactions are stored in the variable `tx_prev_month_all_prev_year`.\n",
    "\n",
    "The subsequent `WITH` clause is particular because, instead of counting the `tx_prev_month_all_prev_year` and summing their amounts, it returns `NULL` for both values, if no transactions are found in the history. This is useful for differentiating, in the final result, customers for whom no significant transaction history is found (and therefore no calculations can be made) from those for whom a history is available (and calculations can proceed as required by the query).\n",
    "\n",
    "The next `WITH` clause calculates the averages of the just computed results `tx_prev_month_prev_year_total_amount` and `tx_prev_month_prev_year_montly_freq` obtaining  `tx_prev_month_all_prev_year_total_amount_avg` and `tx_prev_month_all_prev_year_montly_freq_avg`. The `AVG` operator preserves the `NULL` value when calculating based on `NULL`; thus, if there are no transactions, `AVG(NULL)` will return `NULL`.\n",
    "\n",
    "The last `OPTIONAL MATCH` performs the same calculations as the previous one, but now on transactions `tx` that have same month and year as `first_of_previous_month`. Unlike before, distinguishing between customers with and without transactions is not required at this stage, as this distinction will be handled in the `RETURN` clause by referencing the historical data.\n",
    "\n",
    "The last `WITH` calculates `total_amount_prev_month` and `monthly_freq_prev_month`, which represent the total transactions amount and transaction frequency of all the `tx`s. These two values are then used in the `RETURN` stage to determine if they fall below the usual average transactions amounts and frequency.\n",
    "\n",
    "In the `RETURN` statement, if the customer has historical data for the same period (indicated by `tx_prev_month_all_prev_year_monthly_freq_avg IS NOT NULL`), we proceed to check whether `total_amount_prev_month < tx_prev_month_all_prev_year_total_amount_avg` and `monthly_freq_prev_month < tx_prev_month_all_prev_year_monthly_freq_avg`. It is important to note that, in this scenario, the customer may not have any `tx`s. However, since historical data is available, the absence of `tx`s does not indicate missing data in the database. Instead, it signifies that the customer did not perform any transactions during the same month and year as `first_of_previous_month`.\n",
    "\n",
    "If a customer hasn't the same period historical data we cannot provide any meaningful response so we repond with `NULL` value in both column `is_under_total_amount_avg_of_same_period` and `is_under_monthly_freq_avg_of_same_period`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d7b78d7-88dd-47ef-8320-94f6655c6984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.AggregationSkippedNull} {category: UNRECOGNIZED} {title: The query contains an aggregation function that skips null values.} {description: null value eliminated in set function.} {position: None} for query: '\\n            WITH date.truncate(\\'month\\', date(\"2023-05\" + \"-01\") ) - duration({months: 1}) AS first_of_previous_month\\n            \\n            MATCH (c:Customer)\\n\\n            OPTIONAL MATCH (c)-[tx_prev_month_all_prev_year:Make_transaction]->(:Terminal)\\n            WHERE \\n                tx_prev_month_all_prev_year.tx_date_month = first_of_previous_month.month\\n                AND tx_prev_month_all_prev_year.tx_date_year < first_of_previous_month.year\\n            WITH\\n                first_of_previous_month,\\n                c,\\n                tx_prev_month_all_prev_year.tx_date_year as year, \\n                CASE \\n                    WHEN COUNT(tx_prev_month_all_prev_year)>0 THEN SUM(tx_prev_month_all_prev_year.tx_amount)\\n                    ELSE NULL\\n                END AS tx_prev_month_prev_year_total_amount, \\n\\n                CASE \\n                    WHEN  COUNT(tx_prev_month_all_prev_year)>0 THEN COUNT(tx_prev_month_all_prev_year)\\n                    ELSE NULL\\n                END AS tx_prev_month_prev_year_montly_freq\\n            WITH\\n            first_of_previous_month,\\n            c, \\n            AVG(tx_prev_month_prev_year_total_amount) AS tx_prev_month_all_prev_year_total_amount_avg, \\n            AVG(tx_prev_month_prev_year_montly_freq) AS tx_prev_month_all_prev_year_montly_freq_avg\\n\\n            OPTIONAL MATCH (c)-[tx:Make_transaction]->(:Terminal)\\n            WHERE \\n                tx.tx_date_month = first_of_previous_month.month AND \\n                tx.tx_date_year = first_of_previous_month.year\\n            WITH\\n                c,\\n                SUM(tx.tx_amount) AS total_amount_prev_month, \\n                COUNT(tx) AS monthly_freq_prev_month,\\n                tx_prev_month_all_prev_year_total_amount_avg,\\n                tx_prev_month_all_prev_year_montly_freq_avg\\n\\n            RETURN\\n                c,\\n\\n                CASE \\n                    WHEN tx_prev_month_all_prev_year_total_amount_avg IS NULL THEN NULL\\n                    ELSE total_amount_prev_month < tx_prev_month_all_prev_year_total_amount_avg\\n                END AS is_under_total_amount_avg_of_same_period,\\n\\n                CASE \\n                    WHEN tx_prev_month_all_prev_year_montly_freq_avg IS NULL THEN NULL\\n                    ELSE monthly_freq_prev_month < tx_prev_month_all_prev_year_montly_freq_avg\\n                END AS is_under_monthly_freq_avg_of_same_period\\n    '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_a1 execution time: 4.22s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>is_under_total_amount_avg_of_same_period</th>\n",
       "      <th>is_under_monthly_freq_avg_of_same_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     c  \\\n",
       "0    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "1    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "2    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "3    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "4    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "..                                                 ...   \n",
       "995  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "996  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "997  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "998  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "999  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "\n",
       "    is_under_total_amount_avg_of_same_period  \\\n",
       "0                                       True   \n",
       "1                                       True   \n",
       "2                                       True   \n",
       "3                                       None   \n",
       "4                                      False   \n",
       "..                                       ...   \n",
       "995                                    False   \n",
       "996                                     True   \n",
       "997                                    False   \n",
       "998                                     True   \n",
       "999                                    False   \n",
       "\n",
       "    is_under_monthly_freq_avg_of_same_period  \n",
       "0                                       True  \n",
       "1                                       True  \n",
       "2                                       True  \n",
       "3                                       None  \n",
       "4                                      False  \n",
       "..                                       ...  \n",
       "995                                     True  \n",
       "996                                     True  \n",
       "997                                    False  \n",
       "998                                    False  \n",
       "999                                    False  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#year_and_month_under_analesis is a string that contains a year and a month in the format yyyy-MM\n",
    "def query_a1(year_and_month_under_analesis):\n",
    "    query = f\"\"\"\n",
    "            WITH date.truncate('month', date(\"{year_and_month_under_analesis}\" + \"-01\") ) - duration({{months: 1}}) AS first_of_previous_month\n",
    "            \n",
    "            MATCH (c:Customer)\n",
    "\n",
    "            OPTIONAL MATCH (c)-[tx_prev_month_all_prev_year:Make_transaction]->(:Terminal)\n",
    "            WHERE \n",
    "                tx_prev_month_all_prev_year.tx_date_month = first_of_previous_month.month\n",
    "                AND tx_prev_month_all_prev_year.tx_date_year < first_of_previous_month.year\n",
    "            WITH\n",
    "                first_of_previous_month,\n",
    "                c,\n",
    "                tx_prev_month_all_prev_year.tx_date_year as year, \n",
    "                CASE \n",
    "                    WHEN COUNT(tx_prev_month_all_prev_year)>0 THEN SUM(tx_prev_month_all_prev_year.tx_amount)\n",
    "                    ELSE NULL\n",
    "                END AS tx_prev_month_prev_year_total_amount, \n",
    "\n",
    "                CASE \n",
    "                    WHEN  COUNT(tx_prev_month_all_prev_year)>0 THEN COUNT(tx_prev_month_all_prev_year)\n",
    "                    ELSE NULL\n",
    "                END AS tx_prev_month_prev_year_montly_freq\n",
    "            WITH\n",
    "            first_of_previous_month,\n",
    "            c, \n",
    "            AVG(tx_prev_month_prev_year_total_amount) AS tx_prev_month_all_prev_year_total_amount_avg, \n",
    "            AVG(tx_prev_month_prev_year_montly_freq) AS tx_prev_month_all_prev_year_montly_freq_avg\n",
    "\n",
    "            OPTIONAL MATCH (c)-[tx:Make_transaction]->(:Terminal)\n",
    "            WHERE \n",
    "                tx.tx_date_month = first_of_previous_month.month AND \n",
    "                tx.tx_date_year = first_of_previous_month.year\n",
    "            WITH\n",
    "                c,\n",
    "                SUM(tx.tx_amount) AS total_amount_prev_month, \n",
    "                COUNT(tx) AS monthly_freq_prev_month,\n",
    "                tx_prev_month_all_prev_year_total_amount_avg,\n",
    "                tx_prev_month_all_prev_year_montly_freq_avg\n",
    "\n",
    "            RETURN\n",
    "                c,\n",
    "\n",
    "                CASE \n",
    "                    WHEN tx_prev_month_all_prev_year_total_amount_avg IS NULL THEN NULL\n",
    "                    ELSE total_amount_prev_month < tx_prev_month_all_prev_year_total_amount_avg\n",
    "                END AS is_under_total_amount_avg_of_same_period,\n",
    "\n",
    "                CASE \n",
    "                    WHEN tx_prev_month_all_prev_year_montly_freq_avg IS NULL THEN NULL\n",
    "                    ELSE monthly_freq_prev_month < tx_prev_month_all_prev_year_montly_freq_avg\n",
    "                END AS is_under_monthly_freq_avg_of_same_period\n",
    "    \"\"\"\n",
    "\n",
    "    return execute_query_df(\"query_a1\",query)\n",
    "\n",
    "month_and_year_under_analesis = \"2023-05\"\n",
    "query_a1(month_and_year_under_analesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa63752-1b6a-45d7-a369-d4105a3b2af5",
   "metadata": {},
   "source": [
    "#### 5.1.3) A1 Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c1145-46af-42c6-bc35-746eaf941ddc",
   "metadata": {},
   "source": [
    "To improve the query performance since it fiters the data on `make_transaction.tx_date_month` and `make_transaction.tx_date_year` we can build a compound index on these two fiels\n",
    "after that we can call again the query passing the same argument and look at the execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5beb648-9448-4bcd-a68e-3691b213d87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_composite_index_if_not_exists_on_Make_transaction_tx_date_month_and_tx_date_year execution time: 0.45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_composite_index_if_not_exists_on_Make_transaction_tx_date_month_and_tx_date_year():\n",
    "    query = \"CREATE INDEX composite_index_on_tx_date_year_and_month IF NOT EXISTS FOR ()-[tx:Make_transaction]-() ON (tx.tx_date_month, tx.tx_date_year)\"\n",
    "    return execute_query_command(\"create_composite_index_if_not_exists_on_Make_transaction_tx_date_month_and_tx_date_year\", query)\n",
    "\n",
    "create_composite_index_if_not_exists_on_Make_transaction_tx_date_month_and_tx_date_year()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e77c988-6f70-4ad0-a490-1d7cc91ae759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.AggregationSkippedNull} {category: UNRECOGNIZED} {title: The query contains an aggregation function that skips null values.} {description: null value eliminated in set function.} {position: None} for query: '\\n            WITH date.truncate(\\'month\\', date(\"2026-05\" + \"-01\") ) - duration({months: 1}) AS first_of_previous_month\\n            \\n            MATCH (c:Customer)\\n\\n            OPTIONAL MATCH (c)-[tx_prev_month_all_prev_year:Make_transaction]->(:Terminal)\\n            WHERE \\n                tx_prev_month_all_prev_year.tx_date_month = first_of_previous_month.month\\n                AND tx_prev_month_all_prev_year.tx_date_year < first_of_previous_month.year\\n            WITH\\n                first_of_previous_month,\\n                c,\\n                tx_prev_month_all_prev_year.tx_date_year as year, \\n                CASE \\n                    WHEN COUNT(tx_prev_month_all_prev_year)>0 THEN SUM(tx_prev_month_all_prev_year.tx_amount)\\n                    ELSE NULL\\n                END AS tx_prev_month_prev_year_total_amount, \\n\\n                CASE \\n                    WHEN  COUNT(tx_prev_month_all_prev_year)>0 THEN COUNT(tx_prev_month_all_prev_year)\\n                    ELSE NULL\\n                END AS tx_prev_month_prev_year_montly_freq\\n            WITH\\n            first_of_previous_month,\\n            c, \\n            AVG(tx_prev_month_prev_year_total_amount) AS tx_prev_month_all_prev_year_total_amount_avg, \\n            AVG(tx_prev_month_prev_year_montly_freq) AS tx_prev_month_all_prev_year_montly_freq_avg\\n\\n            OPTIONAL MATCH (c)-[tx:Make_transaction]->(:Terminal)\\n            WHERE \\n                tx.tx_date_month = first_of_previous_month.month AND \\n                tx.tx_date_year = first_of_previous_month.year\\n            WITH\\n                c,\\n                SUM(tx.tx_amount) AS total_amount_prev_month, \\n                COUNT(tx) AS monthly_freq_prev_month,\\n                tx_prev_month_all_prev_year_total_amount_avg,\\n                tx_prev_month_all_prev_year_montly_freq_avg\\n\\n            RETURN\\n                c,\\n\\n                CASE \\n                    WHEN tx_prev_month_all_prev_year_total_amount_avg IS NULL THEN NULL\\n                    ELSE total_amount_prev_month < tx_prev_month_all_prev_year_total_amount_avg\\n                END AS is_under_total_amount_avg_of_same_period,\\n\\n                CASE \\n                    WHEN tx_prev_month_all_prev_year_montly_freq_avg IS NULL THEN NULL\\n                    ELSE monthly_freq_prev_month < tx_prev_month_all_prev_year_montly_freq_avg\\n                END AS is_under_monthly_freq_avg_of_same_period\\n    '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_a1 execution time: 6.61s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>is_under_total_amount_avg_of_same_period</th>\n",
       "      <th>is_under_monthly_freq_avg_of_same_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     c  \\\n",
       "0    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "1    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "2    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "3    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "4    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "..                                                 ...   \n",
       "995  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "996  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "997  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "998  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "999  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "\n",
       "    is_under_total_amount_avg_of_same_period  \\\n",
       "0                                       True   \n",
       "1                                       True   \n",
       "2                                       True   \n",
       "3                                       True   \n",
       "4                                       True   \n",
       "..                                       ...   \n",
       "995                                     True   \n",
       "996                                     True   \n",
       "997                                     True   \n",
       "998                                     True   \n",
       "999                                     True   \n",
       "\n",
       "    is_under_monthly_freq_avg_of_same_period  \n",
       "0                                       True  \n",
       "1                                       True  \n",
       "2                                       True  \n",
       "3                                       True  \n",
       "4                                       True  \n",
       "..                                       ...  \n",
       "995                                     True  \n",
       "996                                     True  \n",
       "997                                     True  \n",
       "998                                     True  \n",
       "999                                     True  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_a1(month_and_year_under_analesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9086f3-1741-45ca-9f8d-3b9b35428042",
   "metadata": {},
   "source": [
    "As shown in the execution plan image below, the query is not utilizing the index at all! This occurs because, in the initial `MATCH` clause, we are not directly filtering the transactions. Instead, we first match the customers, which prevents the query from leveraging the index efficiently.  \n",
    "\n",
    "In fact, the only index used is on the customers, and it is applied merely to retrieve all customer nodes without performing any filtering. Regarding transactions, no index is utilized either in the initial filtering or in the subsequent `OPTIONAL MATCH`, further contributing to the inefficiency of the query.  \n",
    "\n",
    "To generate the execution plan shown in the image, you simply need to prefix the query with the word `EXPLAIN` in Neo4j.  \n",
    "\n",
    "<img src=\"./assets/Execution plan query A1.svg\" style=\"width:600px;\">\n",
    "\n",
    "#### 5.1.4) A2 query code\n",
    "By slightly modifying the query to omit the \"for all customers\" clause and displaying only customers with historical data, we can significantly improve performance by leveraging the index. This optimization involves removing the initial `MATCH` clause, turning the second `OPTIONAL MATCH` into a regular `MATCH`.  \n",
    "\n",
    "This change means that the results will no longer include customers with `NULL` values in columns `tx_prev_month_all_prev_year_total_amount_avg` and `tx_prev_month_all_prev_year_montly_freq_avg`, as these customers will be excluded directly by the first `MATCH` clause.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e1ba842-727c-41a5-9d17-4e09cd7f9606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.AggregationSkippedNull} {category: UNRECOGNIZED} {title: The query contains an aggregation function that skips null values.} {description: null value eliminated in set function.} {position: None} for query: '\\n            WITH date.truncate(\\'month\\', date(\"2023-05\" + \"-01\") ) - duration({months: 1}) AS first_of_previous_month\\n\\n            MATCH (c)-[tx_prev_month_all_prev_year:Make_transaction]->(:Terminal)\\n            WHERE \\n                tx_prev_month_all_prev_year.tx_date_month = first_of_previous_month.month\\n                AND tx_prev_month_all_prev_year.tx_date_year < first_of_previous_month.year\\n            WITH\\n                first_of_previous_month,\\n                c,\\n                tx_prev_month_all_prev_year.tx_date_year as year,\\n                SUM(tx_prev_month_all_prev_year.tx_amount)  AS tx_prev_month_prev_year_total_amount, \\n                COUNT(tx_prev_month_all_prev_year) AS tx_prev_month_prev_year_montly_freq\\n            WITH\\n            first_of_previous_month,\\n            c, \\n            AVG(tx_prev_month_prev_year_total_amount) AS tx_prev_month_all_prev_year_total_amount_avg, \\n            AVG(tx_prev_month_prev_year_montly_freq) AS tx_prev_month_all_prev_year_montly_freq_avg\\n\\n            OPTIONAL MATCH (c)-[tx:Make_transaction]->(:Terminal)\\n            WHERE \\n                tx.tx_date_month = first_of_previous_month.month AND \\n                tx.tx_date_year = first_of_previous_month.year\\n            WITH\\n                c,\\n                SUM(tx.tx_amount) AS total_amount_prev_month, \\n                COUNT(tx) AS monthly_freq_prev_month,\\n                tx_prev_month_all_prev_year_total_amount_avg,\\n                tx_prev_month_all_prev_year_montly_freq_avg\\n\\n            RETURN\\n                c, \\n                total_amount_prev_month < tx_prev_month_all_prev_year_total_amount_avg  AS is_under_total_amount_avg_of_same_period,\\n                monthly_freq_prev_month < tx_prev_month_all_prev_year_montly_freq_avg AS is_under_monthly_freq_avg_of_same_period\\n            '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_a2 execution time: 2.49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>is_under_total_amount_avg_of_same_period</th>\n",
       "      <th>is_under_monthly_freq_avg_of_same_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>(mean_amount, x_customer_id, mean_nb_tx_per_da...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>934 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     c  \\\n",
       "0    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "1    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "2    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "3    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "4    (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "..                                                 ...   \n",
       "929  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "930  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "931  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "932  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "933  (mean_amount, x_customer_id, mean_nb_tx_per_da...   \n",
       "\n",
       "     is_under_total_amount_avg_of_same_period  \\\n",
       "0                                        True   \n",
       "1                                        True   \n",
       "2                                        True   \n",
       "3                                        True   \n",
       "4                                        True   \n",
       "..                                        ...   \n",
       "929                                      True   \n",
       "930                                     False   \n",
       "931                                     False   \n",
       "932                                     False   \n",
       "933                                      True   \n",
       "\n",
       "     is_under_monthly_freq_avg_of_same_period  \n",
       "0                                        True  \n",
       "1                                        True  \n",
       "2                                        True  \n",
       "3                                        True  \n",
       "4                                       False  \n",
       "..                                        ...  \n",
       "929                                     False  \n",
       "930                                     False  \n",
       "931                                     False  \n",
       "932                                     False  \n",
       "933                                      True  \n",
       "\n",
       "[934 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#year_and_month_under_analesis is a string that contains a year and a month in the format yyyy-MM\n",
    "def query_a2(year_and_month_under_analesis):\n",
    "    query = f\"\"\"\n",
    "            WITH date.truncate('month', date(\"{year_and_month_under_analesis}\" + \"-01\") ) - duration({{months: 1}}) AS first_of_previous_month\n",
    "\n",
    "            MATCH (c)-[tx_prev_month_all_prev_year:Make_transaction]->(:Terminal)\n",
    "            WHERE \n",
    "                tx_prev_month_all_prev_year.tx_date_month = first_of_previous_month.month\n",
    "                AND tx_prev_month_all_prev_year.tx_date_year < first_of_previous_month.year\n",
    "            WITH\n",
    "                first_of_previous_month,\n",
    "                c,\n",
    "                tx_prev_month_all_prev_year.tx_date_year as year,\n",
    "                SUM(tx_prev_month_all_prev_year.tx_amount)  AS tx_prev_month_prev_year_total_amount, \n",
    "                COUNT(tx_prev_month_all_prev_year) AS tx_prev_month_prev_year_montly_freq\n",
    "            WITH\n",
    "            first_of_previous_month,\n",
    "            c, \n",
    "            AVG(tx_prev_month_prev_year_total_amount) AS tx_prev_month_all_prev_year_total_amount_avg, \n",
    "            AVG(tx_prev_month_prev_year_montly_freq) AS tx_prev_month_all_prev_year_montly_freq_avg\n",
    "\n",
    "            OPTIONAL MATCH (c)-[tx:Make_transaction]->(:Terminal)\n",
    "            WHERE \n",
    "                tx.tx_date_month = first_of_previous_month.month AND \n",
    "                tx.tx_date_year = first_of_previous_month.year\n",
    "            WITH\n",
    "                c,\n",
    "                SUM(tx.tx_amount) AS total_amount_prev_month, \n",
    "                COUNT(tx) AS monthly_freq_prev_month,\n",
    "                tx_prev_month_all_prev_year_total_amount_avg,\n",
    "                tx_prev_month_all_prev_year_montly_freq_avg\n",
    "\n",
    "            RETURN\n",
    "                c, \n",
    "                total_amount_prev_month < tx_prev_month_all_prev_year_total_amount_avg  AS is_under_total_amount_avg_of_same_period,\n",
    "                monthly_freq_prev_month < tx_prev_month_all_prev_year_montly_freq_avg AS is_under_monthly_freq_avg_of_same_period\n",
    "            \"\"\"\n",
    "    \n",
    "    return execute_query_df(\"query_a2\",query)\n",
    "query_a2(month_and_year_under_analesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476082d2-7dc3-46ba-a145-4ddb99a62de7",
   "metadata": {},
   "source": [
    "#### 5.1.5) A2 Performances\n",
    "As shown in the execution plan image below, the query is now utilizing the index we specifically created for filtering transactions. Unlike the initial version, where no index was used on the transactions, this optimized approach ensures that the query leverages the index effectively to improve performance during the filtering process.\n",
    "\n",
    "<img src=\"./assets/Execution plan query A2.svg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ad3fc2-d9ea-4d44-a734-6ab076d36be7",
   "metadata": {},
   "source": [
    "### 5.2) Query B\n",
    "#### 5.2.1) Query request\n",
    "> For each terminal identify the possible fraudulent transactions. The fraudulent transactions are those whose import is higher than 20% of the maximal import of the transactions executed on the same terminal in the last month.\n",
    "\n",
    "- \"For each terminal\": This indicates that the query results must include all terminals, even those for which it is not possible to identify any fraudulent transactions.\n",
    "\n",
    "- \"In the last month\": refers to data from the month preceding the one provided as a parameter. Similar to the previous query, this query is also parameterized by allowing a partial date in the \"yyyy-MM\" format to be passed to the python. This date is used to calculate the `first_of_previous_month` variable, which represents the first day of the month prior to the given date. Additionally, the query includes a reference to the first day of the current month, stored in the `today` variable, for further calculations or filtering as needed. \n",
    "\n",
    "#### 5.1.2) B1 Query Code\n",
    "The query begins by saving the provided date into the today variable and computing the first day of the previous month, which is stored in `first_of_previous_month`. \n",
    "\n",
    "Next, all terminals are matched to ensure that none are excluded from the final result of the query. This is done because the following `WHERE` clauses do not filter out terminals, and all subsequent matches are `OPTIONAL MATCH`.\n",
    "\n",
    "The first `OPTIONAL MATCH` retrieves transactions made on terminals during the month and year corresponding to `first_of_previous_month`. These transactions are saved in the `tx_prev_month` variable. However, some terminals may not have any transactions for the specified period, and in those cases, `tx_prev_month` will remain empty for those terminals.\n",
    "\n",
    "Following this, the query calculates the fraud detection threshold using a `WITH` statement. The fraud amount limit, stored in the variable `tx_amount_fraud_limit`, is defined as 20% more than the maximum transaction amount from the previous month. For terminals where no transactions were found in `tx_prev_month`, the fraud amount limit remains `NULL`.\n",
    "\n",
    "The next step uses another `OPTIONAL MATCH` to retrieve transactions for the current month, filtering by the same month and year as `today`. These transactions are stored in the `tx_current_month` variable. Using the calculated fraud amount limit, the query identifies fraudulent transactions by collecting those in `tx_current_month` where the transaction amount exceeds `tx_amount_fraud_limit`. This collection is saved in `fraud_txs_current_month`. If `tx_amount_fraud_limit` is `NULL`, the condition will always evaluate to false, resulting in an empty collection for the terminal.\n",
    "\n",
    "Finally, the `RETURN` statement distinguishes between two problematic cases when a terminal has an empty `fraud_txs_current_month` collection. In the first case, the fraud amount limit could not be calculated, making it impossible to determine whether the terminal had fraudulent transactions. In the second case, the limit was calculated, but no fraudulent transactions were identified for that terminal in the current month. To address this ambiguity, the query replaces empty collections in `fraud_txs_current_month` with the value `NULL` whenever `tx_amount_fraud_limit IS NULL`. This approach ensures clarity in the results, differentiating between the two scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31f3bfcc-2c64-4640-b515-3d3d9346c817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.AggregationSkippedNull} {category: UNRECOGNIZED} {title: The query contains an aggregation function that skips null values.} {description: null value eliminated in set function.} {position: None} for query: '\\n            WITH date(\"2023-05\" + \"-01\") AS today\\n            WITH today, date.truncate(\\'month\\', today ) - duration({months: 1}) AS first_of_previous_month\\n\\n            MATCH (t:Terminal)\\n\\n            OPTIONAL MATCH (:Customer)-[tx_prev_month:Make_transaction]->(t)\\n            WHERE \\n                tx_prev_month.tx_date_month = first_of_previous_month.month\\n                AND tx_prev_month.tx_date_year = first_of_previous_month.year\\n\\n            with today, t, max(tx_prev_month.tx_amount) * 1.2 as tx_amount_fraud_limit\\n\\n            OPTIONAL MATCH (:Customer)-[tx_current_month:Make_transaction]->(t)\\n            WHERE \\n                tx_current_month.tx_date_month = today.month\\n                AND tx_current_month.tx_date_year = today.year\\n\\n            WITH \\n                t, \\n                tx_amount_fraud_limit,\\n                COLLECT(CASE \\n                    WHEN tx_current_month.tx_amount > tx_amount_fraud_limit THEN tx_current_month \\n                    ELSE NULL \\n                END) AS fraud_txs_current_month\\n\\n            RETURN \\n                t, \\n                CASE \\n                    WHEN tx_amount_fraud_limit IS NULL THEN NULL\\n                    ELSE fraud_txs_current_month\\n                END AS fraud_txs_current_month\\n            '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_b1 execution time: 4.25s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>fraud_txs_current_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[(transaction_id, tx_date_year, tx_time_days, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>(y_terminal_id, terminal_id, x_terminal_id)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               t  \\\n",
       "0    (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "1    (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "2    (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "3    (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "4    (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "..                                           ...   \n",
       "495  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "496  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "497  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "498  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "499  (y_terminal_id, terminal_id, x_terminal_id)   \n",
       "\n",
       "                               fraud_txs_current_month  \n",
       "0                                                   []  \n",
       "1                                                   []  \n",
       "2                                                   []  \n",
       "3                                                   []  \n",
       "4                                                   []  \n",
       "..                                                 ...  \n",
       "495  [(transaction_id, tx_date_year, tx_time_days, ...  \n",
       "496                                                 []  \n",
       "497                                                 []  \n",
       "498                                                 []  \n",
       "499                                                 []  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#year_and_month_under_analesis is a string that contains a year and a month in the format yyyy-MM\n",
    "def query_b1(year_and_month_under_analesis):\n",
    "    query = f\"\"\"\n",
    "            WITH date(\"{year_and_month_under_analesis}\" + \"-01\") AS today\n",
    "            WITH today, date.truncate('month', today ) - duration({{months: 1}}) AS first_of_previous_month\n",
    "\n",
    "            MATCH (t:Terminal)\n",
    "\n",
    "            OPTIONAL MATCH (:Customer)-[tx_prev_month:Make_transaction]->(t)\n",
    "            WHERE \n",
    "                tx_prev_month.tx_date_month = first_of_previous_month.month\n",
    "                AND tx_prev_month.tx_date_year = first_of_previous_month.year\n",
    "\n",
    "            with today, t, max(tx_prev_month.tx_amount) * 1.2 as tx_amount_fraud_limit\n",
    "\n",
    "            OPTIONAL MATCH (:Customer)-[tx_current_month:Make_transaction]->(t)\n",
    "            WHERE \n",
    "                tx_current_month.tx_date_month = today.month\n",
    "                AND tx_current_month.tx_date_year = today.year\n",
    "\n",
    "            WITH \n",
    "                t, \n",
    "                tx_amount_fraud_limit,\n",
    "                COLLECT(CASE \n",
    "                    WHEN tx_current_month.tx_amount > tx_amount_fraud_limit THEN tx_current_month \n",
    "                    ELSE NULL \n",
    "                END) AS fraud_txs_current_month\n",
    "\n",
    "            RETURN \n",
    "                t, \n",
    "                CASE \n",
    "                    WHEN tx_amount_fraud_limit IS NULL THEN NULL\n",
    "                    ELSE fraud_txs_current_month\n",
    "                END AS fraud_txs_current_month\n",
    "            \"\"\"\n",
    "\n",
    "    return execute_query_df(\"query_b1\",query)\n",
    "query_b1(month_and_year_under_analesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e54644-ad05-4920-a6a5-8816e6aa4e1c",
   "metadata": {},
   "source": [
    "#### 5.1.3) B1 Performances\n",
    "As we can see in the execution plan of the query shown below, the same behavior observed in the previous query occurs here as well. Specifically, the first `MATCH` clause, which matches all terminals, prevents the index from being used to filter the transactions.  \n",
    "\n",
    "In fact, the only index used is on the terminals, and it is applied merely to retrieve all terminals nodes without performing any filtering. Regarding transactions, no index is utilized either in the initial filtering or in the subsequent `OPTIONAL MATCH`, further contributing to the inefficiency of the query.  \n",
    "\n",
    "<img src=\"./assets/Execution plan query B1.svg\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f7927-bb15-46bd-a42c-1bd31bd9152b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
